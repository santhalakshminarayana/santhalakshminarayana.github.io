<!DOCTYPE html><html lang="en"><head><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Maven+Pro&amp;family=Share+Tech+Mono&amp;family=Source+Sans+Pro&amp;family=Ubuntu&amp;display=swap" data-optimized-fonts="true"/><meta charSet="utf-8" class="jsx-2919899820"/><meta name="viewport" content="width=device-width, initial-scale=1" class="jsx-2919899820"/><meta name="description" content="I&#x27;m Santha Lakshmi Narayana, a voyager on mission exploring digital universe to understand how it works." class="jsx-2919899820"/><meta name="author" content="Santha Lakshmi Narayana" class="jsx-2919899820"/><meta name="keywords" content="Blog,Tutorial,Python,Javascript" class="jsx-2919899820"/><meta property="og:title" content="Santha Lakshmi Narayana" class="jsx-2919899820"/><meta property="og:description" content="I&#x27;m Santha Lakshmi Narayana, a voyager on mission exploring digital universe to understand how it works." class="jsx-2919899820"/><meta property="og:url" content="https://santhalakshminarayana.github.io/" class="jsx-2919899820"/><meta property="og:image" content="https://santhalakshminarayana.github.io/images/santha lakshmi narayana logo.png" class="jsx-2919899820"/><meta property="og:type" content="article" class="jsx-2919899820"/><meta property="og:article:publisher" content="https://santhalakshminarayana.github.io/" class="jsx-2919899820"/><meta property="og:site_name" content="Santha Lakshmi Narayana" class="jsx-2919899820"/><meta name="twitter:card" content="summary" class="jsx-2919899820"/><meta name="twitter:title" content="Santha Lakshmi Narayana" class="jsx-2919899820"/><meta name="twitter:description" content="I&#x27;m Santha Lakshmi Narayana, a voyager on mission exploring digital universe to understand how it works." class="jsx-2919899820"/><meta name="twitter:url" content="https://santhalakshminarayana.github.io/" class="jsx-2919899820"/><meta name="twitter:site" content="@santhalakshminarayana" class="jsx-2919899820"/><meta name="twitter:image" content="https://santhalakshminarayana.github.io/images/santha lakshmi narayana logo.png" class="jsx-2919899820"/><meta name="twitter:creator" content="@santhalakshminarayana" class="jsx-2919899820"/><link rel="icon" href="/images/santha-lakshmi-narayana-logo.png?" class="jsx-2919899820"/><link rel="canonical" href="https://santhalakshminarayana.github.io/" class="jsx-2919899820"/><meta name="google-site-verification" content="3p5W6wHr-TDhnkyuewv0nYJd2S9OuTQlj5__OUyLLcU" class="jsx-2919899820"/><title class="jsx-2919899820">Santha Lakshmi Narayana</title><meta name="next-head-count" content="24"/><link rel="preload" href="/_next/static/css/b1be9be44572118d40d2.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b1be9be44572118d40d2.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-a40ef1678bae11e696dba45124eadd70.js"></script><script src="/_next/static/chunks/webpack-2b6f4fb4c650415a78b4.js" defer=""></script><script src="/_next/static/chunks/framework.1b3b121feae4c8ce410b.js" defer=""></script><script src="/_next/static/chunks/commons.0b859a3345ec2e88e2a5.js" defer=""></script><script src="/_next/static/chunks/main-67d63c42ee5e57873b20.js" defer=""></script><script src="/_next/static/chunks/pages/_app-90550e3da438f273bbf6.js" defer=""></script><script src="/_next/static/chunks/d0447323.dff2bc2bb984caa517f9.js" defer=""></script><script src="/_next/static/chunks/773f402080c38a523cb0b4f52dac49b5097e45fc.46d750a4db451d31d371.js" defer=""></script><script src="/_next/static/chunks/6188d020c9511bd1e7ae4c1c2034aa4e99a1704e.a04bde1a83249dda4b09.js" defer=""></script><script src="/_next/static/chunks/pages/index-c77a14160bcd206917fe.js" defer=""></script><script src="/_next/static/pvv6ydTaNkcDcbA_18mts/_buildManifest.js" defer=""></script><script src="/_next/static/pvv6ydTaNkcDcbA_18mts/_ssgManifest.js" defer=""></script><style id="__jsx-1906274153">.tags.jsx-1906274153{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding:1vw 5vw 1vw 5vw;background-color:#fffecb;border-bottom:5px solid #071013;}.tags.jsx-1906274153 a.jsx-1906274153{font-family:'Share Tech Mono',monospace;color:#1d2b35;margin:0 1em 0 1em;-webkit-text-decoration:none;text-decoration:none;border-bottom:1px dashed #fb232e;}.tags.jsx-1906274153 a.jsx-1906274153:hover{background:#20a4f3;color:#fffecb;border-bottom:1px dashed #fffecb;}.tags.jsx-1906274153 a.jsx-1906274153:active{background:#fb232e;}</style><style id="__jsx-286259859">.header-container.jsx-286259859{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;padding:10px 5vw 10px 5vw;background:#1d2b35;}.header-left.jsx-286259859{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}.header-left.jsx-286259859 a.jsx-286259859{font-family:'Source Sans Pro',sans-serif;-webkit-text-decoration:none;text-decoration:none;color:#ffaa33;}img.jsx-286259859{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;width:calc(1.2rem + 1vw);max-width:calc(1.2rem + 1vw);height:auto;margin:0 5px 0 5px;}img.jsx-286259859:hover{cursor:pointer;}.header-left.jsx-286259859 a.jsx-286259859:hover{color:#20a4f3;}.header-left.jsx-286259859 a.jsx-286259859:active{color:#fb232e;}.header-right.jsx-286259859{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:3;-ms-flex:3;flex:3;-webkit-flex-direction:row-reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}.header-right.jsx-286259859 a.jsx-286259859{padding:0 1vw 0 1vw;font-family:'Source Sans Pro',sans-serif;-webkit-text-decoration:none;text-decoration:none;color:#ffaa33;}.header-right.jsx-286259859 a.jsx-286259859:hover{color:#20a4f3;}.header-right.jsx-286259859 a.jsx-286259859:active{color:#fb232e;}@media screen and (max-width:920px){.header-container.jsx-286259859{padding:10px 2vw 10px 2vw;overflow-x:scroll;}#name.jsx-286259859{display:none;}img.jsx-286259859{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}@media screen and (max-width:480px){.header-container.jsx-286259859{padding:10px 2vw 10px 2vw;overflow-x:scroll;}}@media screen and (max-width:300px){img.jsx-286259859{display:none;}}</style><style id="__jsx-1385052749">.card-layout.jsx-1385052749{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;margin:1vh 11vw 1vh 11vw;}.card-container.jsx-1385052749{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:0 1 24vw;-ms-flex:0 1 24vw;flex:0 1 24vw;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;box-sizing:border-box;margin:1vh 0.87vw 1vh 0.87vw;border-bottom:3px solid transparent;}.card-container.jsx-1385052749:hover{border-bottom:3px solid #fb232e;-webkit-transform:scale(0.99);-ms-transform:scale(0.99);transform:scale(0.99);}.img-container.jsx-1385052749{width:100%;max-width:100%;}img.jsx-1385052749{width:100%;max-width:100%;height:12vw;object-fit:cover;border-radius:5px;}.info-container.jsx-1385052749{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:100%;-ms-flex:100%;flex:100%;max-width:100%;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;overflow-wrap:break-word;}.info-container-link.jsx-1385052749{font-family:'Maven Pro',sans-serif;font-weight:bold;font-size:calc(20px + (26 - 20) * ((100vw - 300px) / (1600 - 300)));-webkit-text-decoration:none;text-decoration:none;overflow-wrap:break-word;color:#1d2b35;}.info-container-link.jsx-1385052749:hover{color:#20a4f3;}.info-container-link.jsx-1385052749:active{color:#fb232e;}.description-container.jsx-1385052749{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;max-width:100%;}.description.jsx-1385052749{font-family:'Source Sans Pro',sans-serif;font-size:calc(15px + (18 - 15) * ((100vw - 300px) / (1600 - 300)));color:#071013cc;max-width:100%;}.tags-container.jsx-1385052749{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:100%;-ms-flex:100%;flex:100%;max-width:100%;-webkit-flex-direction:column-reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse;margin:2vh 0 2vh 0;}.tags-container-tag.jsx-1385052749{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;}.tag-link.jsx-1385052749{font-family:'Share Tech Mono',monospace;font-size:calc(14px + (16 - 14) * ((100vw - 300px) / (1600 - 300)));color:#1d2b35;-webkit-text-decoration:none;text-decoration:none;margin-right:1em;border-bottom:1px dashed #fb232e;}.tag-link.jsx-1385052749:hover{background:#20a4f3;color:#fffecb;border-bottom:1px dashed #fffecb;}.tag-link.jsx-1385052749:active{background:#fb232e;}@media screen and (max-width:1100px){.card-layout.jsx-1385052749{-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin:1vh 5vw 1vh 5vw;}.card-container.jsx-1385052749{-webkit-flex:0 1 43vw;-ms-flex:0 1 43vw;flex:0 1 43vw;margin:1vh 1vw 1vh 1vw;}img.jsx-1385052749{width:100%;max-width:100%;height:23vw;object-fit:cover;}}@media screen and (max-width:480px){.card-layout.jsx-1385052749{-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin:1vh 5vw 1vh 5vw;}.card-container.jsx-1385052749{-webkit-flex:0 1 90vw;-ms-flex:0 1 90vw;flex:0 1 90vw;margin:1vh 0 1vh 0;border-bottom:3px solid #fb232e;}img.jsx-1385052749{width:100%;max-width:100%;height:45vw;object-fit:cover;}}</style><style id="__jsx-931837452">.footer-container.jsx-931837452{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;background:#1d2b35f2;padding:1vw 5vw 1vw 5vw;}.footer-container-links.jsx-931837452{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}.footer-links.jsx-931837452{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}.link-item.jsx-931837452{margin:0 1vw 0 1vw;}.link.jsx-931837452{-webkit-text-decoration:none;text-decoration:none;cursor:pointer: background-color:yellow;}.link.jsx-931837452:hover{color:black;}.copy-right-container.jsx-931837452{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;margin-top:10px;}.copy-right-text.jsx-931837452{font-family:'Maven Pro',sans-serif;font-size:calc(0.75rem + 0.1vw);color:#fffecb;}</style><style id="__jsx-2919899820">.header-info.jsx-2919899820{background:#1d2b35;}.greetings.jsx-2919899820{padding:2vw 10vw 2vw 10vw;}.greetings-heading.jsx-2919899820{font-family:'Ubuntu',sans-serif;font-size:2em;text-align:center;color:#ffaa33;}.greetings-statement.jsx-2919899820{font-family:'Ubuntu',sans-serif;font-size:1.5em;padding-top:1vh;text-align:center;color:#ffaa33;}.greetings-tags.jsx-2919899820{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding:1vw 5vw 1vw 5vw;}.posts-display-container.jsx-2919899820{padding:1vh 10vw 1vh 10vw;}.quote.jsx-2919899820{color:#fb232e;font-family:'Ubuntu',sans-serif;font-size:calc(2rem + 0.5vw);}@media screen and (max-width:920px){.greetings-heading.jsx-2919899820{font-size:20px;}.greetings-statement.jsx-2919899820{font-size:18px;}.greetings-tags.jsx-2919899820{display:none;}.posts-display-container.jsx-2919899820{padding:1vh 5vw 1vh 5vh;}}@media screen and (max-width:480px){.greetings-heading.jsx-2919899820{font-size:18px;}.greetings-statement.jsx-2919899820{font-size:16px;}.greetings-tags.jsx-2919899820{display:none;}.posts-display-container.jsx-2919899820{padding:1vh 5vw 1vh 5vh;}}</style><style data-href="https://fonts.googleapis.com/css2?family=Maven+Pro&family=Share+Tech+Mono&family=Source+Sans+Pro&family=Ubuntu&display=swap">@font-face{font-family:'Maven Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/mavenpro/v22/7Auup_AqnyWWAxW2Wk3swUz56MS91Eww8SX25nM.woff) format('woff')}@font-face{font-family:'Share Tech Mono';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sharetechmono/v10/J7aHnp1uDWRBEqV98dVQztYldFc7pw.woff) format('woff')}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xK3dSBYKcSV-LCoeQqfX1RYOo3aPA.woff) format('woff')}@font-face{font-family:'Ubuntu';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/ubuntu/v15/4iCs6KVjbNBYlgo6ew.woff) format('woff')}@font-face{font-family:'Maven Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/mavenpro/v22/7Auup_AqnyWWAxW2Wk3swUz56MS91Eww8SX21nijpBh8CvRBOB1s.woff) format('woff');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Maven Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/mavenpro/v22/7Auup_AqnyWWAxW2Wk3swUz56MS91Eww8SX21nmjpBh8CvRBOB1s.woff) format('woff');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Maven Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/mavenpro/v22/7Auup_AqnyWWAxW2Wk3swUz56MS91Eww8SX21nejpBh8CvRBOA.woff) format('woff');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Share Tech Mono';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sharetechmono/v10/J7aHnp1uDWRBEqV98dVQztYldFcLowEFA87Heg.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNa7lujVj9_mf.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xK3dSBYKcSV-LCoeQqfX1RYOo3qPK7lujVj9_mf.woff2) format('woff2');unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNK7lujVj9_mf.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xK3dSBYKcSV-LCoeQqfX1RYOo3qO67lujVj9_mf.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xK3dSBYKcSV-LCoeQqfX1RYOo3qN67lujVj9_mf.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNq7lujVj9_mf.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xK3dSBYKcSV-LCoeQqfX1RYOo3qOK7lujVj9w.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Ubuntu';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/ubuntu/v15/4iCs6KVjbNBYlgoKcg72nU6AF7xm.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Ubuntu';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/ubuntu/v15/4iCs6KVjbNBYlgoKew72nU6AF7xm.woff2) format('woff2');unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Ubuntu';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/ubuntu/v15/4iCs6KVjbNBYlgoKcw72nU6AF7xm.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Ubuntu';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/ubuntu/v15/4iCs6KVjbNBYlgoKfA72nU6AF7xm.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Ubuntu';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/ubuntu/v15/4iCs6KVjbNBYlgoKcQ72nU6AF7xm.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Ubuntu';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/ubuntu/v15/4iCs6KVjbNBYlgoKfw72nU6AFw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id="__next"><div class="jsx-2919899820"><div class="jsx-2919899820"><div class="jsx-286259859 header"><div class="jsx-286259859 header-container"><div class="jsx-286259859 header-left"><img src="/images/santha-lakshmi-narayana-logo.png" alt="Logo" class="jsx-286259859"/><a id="name" class="jsx-286259859" href="/"><b class="jsx-286259859">Santha Lakshmi Narayana</b></a></div><div class="jsx-286259859 header-right"><a class="jsx-286259859" href="/about">About</a><a href="#" class="jsx-286259859">Tags</a><a class="jsx-286259859" href="/">Home</a></div></div><div style="display:none" class="jsx-286259859"><div class="jsx-1906274153 tags"><a class="jsx-1906274153" href="/tags/image-processing">#image-processing</a><a class="jsx-1906274153" href="/tags/react">#react</a><a class="jsx-1906274153" href="/tags/next-js">#next-js</a><a class="jsx-1906274153" href="/tags/flutter">#flutter</a></div></div></div><div class="jsx-2919899820 header-info"><div class="jsx-2919899820 greetings"><p class="jsx-2919899820 greetings-heading">Greetings, Programs! In the Matrix called Earth.</p><p class="jsx-2919899820 greetings-statement">I&#x27;m Santha Lakshmi Narayana, a voyager on mission exploring the digital universe.</p></div></div><div class="jsx-2919899820 posts-display-container"><p class="jsx-2919899820 quote">All Posts</p></div><div class="jsx-1385052749 card-layout"><div class="jsx-1385052749 card-container"><div class="jsx-1385052749"><div class="jsx-1385052749 img-container"><img src="/images/color-theory/color-theory.jpg" alt="Color Theory" class="jsx-1385052749"/></div><div class="jsx-1385052749 info-container"><div class="jsx-1385052749 description-container"><a class="jsx-1385052749 info-container-link" href="/blog/color-theory">Color Theory</a><p class="jsx-1385052749 description">Different color properties, color models, and color space that are useful in image processing, graphic design, and game design.</p></div><div class="jsx-1385052749 tags-container"><div class="jsx-1385052749 tags-container-tag"><a class="jsx-1385052749 tag-link" href="/tags/image-processing">#image-processing</a></div></div></div></div></div><div class="jsx-1385052749 card-container"><div class="jsx-1385052749"><div class="jsx-1385052749 img-container"><img src="/images/color-science/color-science.jpg" alt="Color Science" class="jsx-1385052749"/></div><div class="jsx-1385052749 info-container"><div class="jsx-1385052749 description-container"><a class="jsx-1385052749 info-container-link" href="/blog/color-science">Color Science</a><p class="jsx-1385052749 description">Understanding the concept of Color from human eye&#x27;s perception to digital world representation.</p></div><div class="jsx-1385052749 tags-container"><div class="jsx-1385052749 tags-container-tag"><a class="jsx-1385052749 tag-link" href="/tags/image-processing">#image-processing</a></div></div></div></div></div><div class="jsx-1385052749 card-container"><div class="jsx-1385052749"><div class="jsx-1385052749 img-container"><img src="/images/note-app-flutter/note-app-in-flutter.jpg" alt="Create a Notes App with Flutter" class="jsx-1385052749"/></div><div class="jsx-1385052749 info-container"><div class="jsx-1385052749 description-container"><a class="jsx-1385052749 info-container-link" href="/blog/create-a-notes-app-with-flutter">Create a Notes App with Flutter</a><p class="jsx-1385052749 description">Create a color-rich Note-taking app with Flutter.</p></div><div class="jsx-1385052749 tags-container"><div class="jsx-1385052749 tags-container-tag"><a class="jsx-1385052749 tag-link" href="/tags/flutter">#flutter</a></div></div></div></div></div><div class="jsx-1385052749 card-container"><div class="jsx-1385052749"><div class="jsx-1385052749 img-container"><img src="/images/blog-nextjs-mdx/nextjs.jpeg" alt="Build Blog with Next.js and MDX &amp; Deploy to Github Pages" class="jsx-1385052749"/></div><div class="jsx-1385052749 info-container"><div class="jsx-1385052749 description-container"><a class="jsx-1385052749 info-container-link" href="/blog/build-blog-with-nextjs-mdx-and-deploy-to-github-pages">Build Blog with Next.js and MDX &amp; Deploy to Github Pages</a><p class="jsx-1385052749 description">Create a blog with Next.js as Static Site Generator, MDX for writing content, Github Pages for deploying the static website. Also add SEO and Image optimization.</p></div><div class="jsx-1385052749 tags-container"><div class="jsx-1385052749 tags-container-tag"><a class="jsx-1385052749 tag-link" href="/tags/react">#react</a><a class="jsx-1385052749 tag-link" href="/tags/next-js">#next-js</a></div></div></div></div></div></div><div class="jsx-931837452 footer-container"><div class="jsx-931837452 footer-container-links"><div class="jsx-931837452 footer-links"><div class="jsx-931837452 link-item"><a href="https://github.com/santhalakshminarayana" rel="noreferrer" target=" _blank" class="jsx-931837452 link"><div><svg stroke="currentColor" fill="currentColor" stroke-width="0" role="img" viewBox="0 0 24 24" style="color:#fffecb;font-size:calc(1rem + 1vw)" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><title></title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></div></a></div><div class="jsx-931837452 link-item"><a href="https://www.linkedin.com/in/santhalakshminarayana/" rel="noreferrer" target="_blank" class="jsx-931837452 link"><div><svg stroke="currentColor" fill="currentColor" stroke-width="0" role="img" viewBox="0 0 24 24" style="color:#fffecb;font-size:calc(1rem + 1vw)" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><title></title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg></div></a></div><div class="jsx-931837452 link-item"><a href="https://medium.com/@santhalakshminarayana/" rel="noreferrer" target="_blank" class="jsx-931837452 link"><div><svg stroke="currentColor" fill="currentColor" stroke-width="0" role="img" viewBox="0 0 24 24" style="color:#fffecb;font-size:calc(1rem + 1vw)" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><title></title><path d="M0 0v24h24V0H0zm19.938 5.686L18.651 6.92a.376.376 0 0 0-.143.362v9.067a.376.376 0 0 0 .143.361l1.257 1.234v.271h-6.322v-.27l1.302-1.265c.128-.128.128-.165.128-.36V8.99l-3.62 9.195h-.49L6.69 8.99v6.163a.85.85 0 0 0 .233.707l1.694 2.054v.271H3.815v-.27L5.51 15.86a.82.82 0 0 0 .218-.707V8.027a.624.624 0 0 0-.203-.527L4.019 5.686v-.27h4.674l3.613 7.923 3.176-7.924h4.456v.271z"></path></svg></div></a></div><div class="jsx-931837452 link-item"><a href="https://www.kaggle.com/santhalnr/" rel="noreferrer" target="_blank" class="jsx-931837452 link"><div><svg stroke="currentColor" fill="currentColor" stroke-width="0" role="img" viewBox="0 0 24 24" style="color:#fffecb;font-size:calc(1rem + 1vw)" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><title></title><path d="M18.825 23.859c-.022.092-.117.141-.281.141h-3.139c-.187 0-.351-.082-.492-.248l-5.178-6.589-1.448 1.374v5.111c0 .235-.117.352-.351.352H5.505c-.236 0-.354-.117-.354-.352V.353c0-.233.118-.353.354-.353h2.431c.234 0 .351.12.351.353v14.343l6.203-6.272c.165-.165.33-.246.495-.246h3.239c.144 0 .236.06.285.18.046.149.034.255-.036.315l-6.555 6.344 6.836 8.507c.095.104.117.208.07.358"></path></svg></div></a></div><div class="jsx-931837452 link-item"><a href="https://www.quora.com/profile/Lakshmi-Narayana-217" rel="noreferrer" target="_blank" class="jsx-931837452 link"><div><svg stroke="currentColor" fill="currentColor" stroke-width="0" role="img" viewBox="0 0 24 24" style="color:#fffecb;font-size:calc(1rem + 1vw)" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><title></title><path d="M12.738 18.701c-.831-1.635-1.805-3.287-3.708-3.287-.362 0-.727.061-1.059.209l-.646-1.289c.786-.678 2.058-1.214 3.693-1.214 2.544 0 3.851 1.229 4.888 2.792.613-1.335.904-3.14.904-5.375 0-5.582-1.744-8.447-5.822-8.447-4.018 0-5.757 2.865-5.757 8.447 0 5.553 1.739 8.389 5.757 8.389.64 0 1.22-.069 1.75-.225zm.996 1.947c-.881.237-1.817.366-2.743.366-5.352 0-10.59-4.269-10.59-10.478C.402 4.271 5.639 0 10.991 0c5.441 0 10.628 4.238 10.628 10.537 0 3.504-1.635 6.351-4.01 8.191.764 1.148 1.543 1.914 2.652 1.914 1.199 0 1.68-.915 1.77-1.649h1.557c.092.974-.402 5.007-4.766 5.007-2.652 0-4.047-1.528-5.096-3.328l.008-.024z"></path></svg></div></a></div></div></div><div class="jsx-931837452 copy-right-container"><p class="jsx-931837452 copy-right-text">Santha Lakshmi Narayana Â© 2021</p></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postsMetaData":[{"metadata":{"title":"Color Theory","description":"Different color properties, color models, and color space that are useful in image processing, graphic design, and game design.","imgName":"color-theory/color-theory.jpg","date":"Sep 14, 2021","tags":["image-processing"],"keywords":["color","color-theory","color-models","color-spaces","graphic-design","image-processing","photography"],"id":"color-theory"},"content":"\n![Color Properties, Models and Spaces](color-theory/color-theory.jpg)\n\n# Color Theory\n\n\u003e Before reading color theory, it is recommended to know about color science that explains how color is defined, represented, and quantified in my previous article about [color science](https://santhalakshminarayana.github.io/blog/color-science)\n\nThe Color theory deals with multiple color terminology, models, and schemes that we use in our daily day-to-day life. The color theory describes relationships between different colors and color schemes. It acts like guidelines for better marketing and design of a product. Color theory is a set of rules that combines art and science. The color theory defines the logical structure of color to create color palettes, color schemes, aesthetically pleasing color designs, and color psychology.\n\nFrom an e-commerce website to an offline store, still photography to a motion picture, interior design to an art gallery, we can see the usage of color theory to attract, please, or astonish the customers.\n\nIn fields like image processing, digital photography, graphic design, and game design, color plays a vital role and one must understand basic color theory concepts like color properties, color models, and color spaces before learning other concepts. \n\n\n## Color Wheel\n\nA color wheel is a set of colors distributed over a circular disc with some rules that signify the meaning of colors. A color wheel can have numerous colors, and generally, a color wheel is a combination of 12 basic colors from primary, secondary, and teritary colors.\n\nHue, saturation and lightness are three elements used to define a color.\n\n## Color Wheel\n\nA color wheel is a set of colors distributed over a circular disc with some rules that signify the meaning of colors. A color wheel can have numerous colors, and generally, a color wheel is a combination of 12 basic colors from primary, secondary, and tertiary colors.\n\nHue, saturation, and lightness are three elements used to define a color.\n\n## Hue\n\nHue is the dominant color among similar colors in a range of the visible spectrum. Hues are the basic colors to which adding white and black produce multiple colors. Hues are generally classified into major colors we see in nature. They are Red, Yellow, Green, Blue, Violet, and Orange. \n\n**Primary colors** - Primary hues are colors that cannot be produced by mixing other hues. In painting world **red**, **yellow**, and **blue** are primary hues. In digital world **red**, **green**, and **blue** are primary colors.\n\n**Secondary colors** - Mixing two primary hues creates secondary hues:\n- **Green** - (Blue + Yellow)\n- **Orange** - (Yellow + Red)\n- **Purple** - (Red + Blue)\n\n**Tertiary colors** - In the color wheel, tertiary hues are mixtures of adjacent primary and secondary hues. Thus, six territory hues are produced.\n- **Chartreuse** - (Yellow + Green)\n- **Teal** - (Green + Blue)\n- **Violet** - (Blue + Purple)\n- **Magenta** - (Purple + Red)\n- **Vermillion** - (Red + Orange)\n- **Amber** - (Orange + Yellow)\n\n![Color Wheel - Primary, Secondary, and Tertiary Hues:=:50:=:Color wheel](color-theory/color-wheel.jpg)\n\n## Saturation/Chroma\n\nSaturation/Chroma is the purity of a hue. It defines the color intensity. A pure color is 100% saturated or fully saturated. Mixing gray (white + black) color to a pure hue decreases the intensity and finally reaches a 0% saturation level. A color can be desaturated by mixing with its complementary color. A hue at 0% saturation is a gray color. Saturation defines a range of color intensities from pure color (100%) to gray (0%). \n\n### Tint\n\nWhen white color is mixed with a color, the resultant is the Tint of that color. Adding white color makes color lighter than the original. The amount of white added defines the tint of color.\n\n![Tints:=:70](color-theory/tints.jpg)\n\n### Shade\n\nA shade of a color is the blackness of the color after being mixed with black color. The shade of a color is darker than the original color.\n\n![Shades:=:70](color-theory/shades.jpg)\n\n### Tone \n\nA Tone is mixing both white and black colors to a color. The resultant color is grayer than the original.\n\n![Tones:=:70](color-theory/tones.jpg)\n\n![Saturation:=:70](color-theory/saturation.jpg)\n\nAlthough Chroma and Saturation speak the same, Chroma is an absolute term that defines color value a range from gray (0%) to pure hue (100%), and saturation defines the brilliance of a color relative to gray.\n\n## Lightness/Luminance\n\nLightness/Luminance define how light (100%) or dark (0%) a color is. All pure hues have a lightness value of 50%. Lightness is measured relative to the brightness of white color. In color perception, lightness tells how much light is reflected from a surface. \n\n![Lightness:=:70](color-theory/lightness.jpg)\n\n---\n\n## Color properties and color terms\n\n### Chromatic \u0026 Achromatic colors\n\nAchromatic colors are colors that have lightness but no hue or saturation. They are black, white and gray. Mixing complementary colors produces achromatic colors.\n\nChromatic colors are the ones that have any amount of hue and saturation. The presence of saturation defines chromatic colors. All other colors except achromatic colors are chromatic colors.\n\n### Chromatic value/Chromatic intensity/Chromaticity\n\nChromatic value/intensity is the measure of how light or dark a color is. Depending on how light or dark a hue is, Tints and Shades of color are created. Chromaticity is similar to saturation as they both speak about how much color is chromatic (a hue with some saturation). Chromaticity is also defined as color independent of lightness (only hue and saturation).\n\n\n### Luminance\n\nLuminance is the intensity of light emitted, reflected, or passes through per unit area in a given direction.\n\n### Brightness\n\nBrightness is a relative term that describes how much light is shining from something. It is the average lightness of an object. It is not a color term but a perception of our eyes created by color's lightness. It is not a quantitative term but can be scaled (%). It is quite similar to luminance in human color vision. [Luminance](http://www.workwithcolor.com/color-luminance-2233.htm) is the brightness of a color perceived by our eyes. A high-intensity color looks more bright. The green color looks more bright than the blue color. A hue with more saturation is brighter than a desaturated hue. A color with the same luminance appears in different brightness depending on the surrounding colors.\n\n### Contrast\n\nContrast is the difference between the luminance of two or more colors placed adjacent or overlapped. High contrast colors appear more bright than low contrast. Generally, contrast is used in the context of foreground and background colors. When equal luminance colors are placed on foreground and background, they look similar and there is no difference observed. Depending on the position of colors in the color wheel, contrast levels vary. Colors next to each other have low contrast and opposite colors have high contrast.\n\n### Color contrast ratio\n\nColor contrast ratio is the quantitative term to define the contrast between two colors. They are measured based on the relative luminance of different colors. The [Web Content Accessibility Guidelines (WCGA)](https://www.w3.org/WAI/WCAG22/Understanding/contrast-minimum.html) published guidelines for calculating contrast ratio of color and these are considered as standard rules in web design.\n\n### Luma\n\nLuma describes the presence of achromatic signal (white, gray, and black) intensity in a color. Luma describes how bright a color is. The difference between luminance and luma is, luminance is derived from linear RGB values, whereas luma is derived from non-linear (gamma-corrected) RGB values. Luminance is based on standard [relative luminance ratios of RGB](https://santhalakshminarayana.github.io/blog/color-science#relative-luminance), and luma is based on relative gamma-corrected RGB ratios.\n\n### Metamerism (Color metameres)\n\nMetamerism occurs when two colors look the same under one lighting condition but, different when light source/conditions change. This usually happens when we buy clothes in a store like a shirt appears light blue in the store but when we brought it in sunlight the shirt looks pale blue. \n\n### Color Temperature\n\nThe color temperature of the light source is the temperature of black-body radiation when black-body is heated at a constant temperature. As the black body observes all spectrum wavelengths, when heated up at a constant temperature, it emits certain wavelengths which are perceived as color. Color temperature is measured in Kelvin (\u0026degK). At different color temperatures, the body is seen as different colors. \n\n![Color Temperature:=:60:=:Colors at different temperatures emitted by a black-body](color-theory/color-temperature.jpg)\n\nThe lower the temperature, the lower the color appears warm, and the higher the temperature, the cooler the color appears.\n\n### Color Rendering Index (CRI)\n\nColor Rendering Index (CRI) is a measurement of how light affects the appearance of a color. It defines how accurately colors can be distinguished under a light source. Light sources with different color temperatures illuminate objects as different colors and sometimes we cannot distinguish object colors in extremely warm or cool light sources. CRI indicates how well a light source can reproduce colors with the same temperature for natural light such as the sun. It is a quantitative term measured on a scale of 0-100. A score of 90 or more is considered excellent and less than 80 is considered poor.\n\nColor temperature and Color Rendering Index (CRI) are two vital terms that affect the selection of light sources and conditions. Art galleries, museums, photographers, and product displays stores choose light sources based on these terms. \n\n---\n\n## Color Harmony or Color schemes\n\nColor harmony is the theory of selecting/combining colors to create a visually pleasing color scheme. Color harmony creates aesthetically rich color combinations that maintain harmony and engages users with the product. The color wheel is the basic logical structure for creating color schemes.\n\n### Monochromatic\n\nThe monochromatic color scheme contains single color with variations of tints, tones, and shades.\n\n![Monochromatic Harmony:=:25:=:Monochromatic Harmony](color-theory/monochromatic.jpg)\n\n### Analogous\n\nAnalogous color schemes are created by grouping the main color with adjacent colors to it in the color wheel.\n\n![Analogous Harmony:=:25:=:Analogous Harmony](color-theory/analogous.jpg)\n\n### Complementary\n\nComplementary colors are two colors selected in a way that colors are opposite to each other in the color wheel.\n\n![Complementary Harmony:=:25:=:Complementary Harmony](color-theory/complementary.jpg)\n\n### Split Complementary\n\nIn the split complementary scheme, the main color is selected and the other two colors are adjacent colors to the complementary color of the main color.\n\n![Split Complementary Harmony:=:25:=:Split Complementary Harmony](color-theory/split-complementary.jpg)\n\n### Triad\n\nTriad is a group of three colors that are equally distant from each other in the color wheel and form a triangle.\n\n![Triad Harmony:=:25:=:Triad Harmony](color-theory/triad.jpg)\n\n### Square\n\nThe square color scheme has four colors that are the same distance to each other forming a square or rhombus in the color. \n\n![Square Harmony:=:25:=:Square Harmony](color-theory/square.jpg)\n\nOther harmonies include diad, diad complementary, rectangle, and polygon schemes.\n\n\n## Color models\n\nColor models are the organization of colors and their mixing (additive or subtractive) based on human color perception. A color model defines color and its properties in a mathematical way.\n\n### RGB\n\nIn the RGB color model, Red, Green, and Blue are three primary colors that are mixed to produce all other colors by [additive color mixing](https://santhalakshminarayana.github.io/blog/color-science#additve-subtractive-color-mixing). Display systems and digital photography stores color values based on RGB model.\n\nBased on the depth (no. of bits allocated to store) of a color, RGB values are scaled in a certain range. For an 8-bit system, the range is 0-255, and when all colors are mixed at minimum level then it designates black color and at maximum level designates white color. If RGB colors are mapped to 3-dimensional space with unit vectors X, Y, and Z-axis as R, G, and B colors, then the vector space forms a cube with all possible colors in it formed by the combination of RGB at different values.\n\n![RGB color model:=:35](color-theory/rgb-cube.jpeg)\n\nWith the RGB model, one cannot easily identify important color terms like lightness, contrast, brightness, tones, tint, and shades.\n\n### HSV (HSB)\n\nHue, Saturation, and Value (or Brightness) (HSV or HSB) is a cylindrical color model that is based on hue, saturation, and brightness described above. \n\nHue is arranged with all hues taking up a certain range in a 0-360 degrees circle. Starting red at 0\u0026deg, green at 120\u0026deg, blue at 240\u0026deg, and again wrapping back to red at 360\u0026deg.\n\nSaturation has a range from 0%-100%, starting from 0% (gray) at the center of the base to 100% (pure color/hue) at the circumference. Saturation controls tints and shades\n\nValue/Brightness also has a range of 0%-100%, with 0 (black) at the bottom of the base to 100% (no black) at the top.\n\n![HSV:=:35](color-theory/hsv.jpeg)\n\nIf brightness is at 0% then the color is black irrespective of hue and saturation. But for white color, the brightness value is 100% and saturation is kept at 0% while hue can be anything.\n\n### HSL\n\nHue, Saturation, and Lightness (HSL) is a bi-cone (double) model while H and S are the same as HSB. \n\n![HSL Cone:=:35](color-theory/hsl-cone.jpeg)\n\nLightness has a range from 0%-100%, starting from 0% (black) at bottom of the cone to 100%(white) at top of the cone. All pure hues have a lightness value of 50%.\n\n![HSL:=:35](color-theory/hsl.jpeg)\n\nColor is white if lightness is 100% irrespective of hue and saturation. Same for black color with lightness at 0% irrespective of hue and saturation values. \n\n## Color spaces\n\nA color space is based on the color model that maps colors to a set of colors like sRGB and Adobe RGB and is reproduced by display systems.\n\n### L\\*a\\*b* (CIELAB) color space \n\nL\\*a\\*b* color space is a device-independent color space in which color is expressed in three components:\n- **L***- Lightness\n- **a***- Green-Red\n- **b***- Blue-Yellow\n\nIt was defined by CIE and also called CIELAB (Lab without * is color space defined by Hunter Lab).\n\nIn L\\*a\\*b\\* color space, L indicates lightness, and a\\* and b\\* indicates chromaticity coordinates. Unlike RGB and HSV, L\\*a\\*b* represents colors in the sphere where L\\*, a\\*, and b\\* are orthogonal axis to each other. CIELAB is a perceptually uniform color space i.e. a standard color system that reflects the color representation close to human vision color perception. \n\n![Lab color space:=:35:=:Lab sphere$$$https://sensing.konicaminolta.asia/what-is-cie-1976-lab-color-space/](color-theory/3d-lab.jpg)\n\nL\\*a\\*b* is based on [opponent process theory](https://santhalakshminarayana.github.io/blog/color-science#opponent-process-theory) where red-green and blue-yellow form opponent pairs. \n\nL\\*-axis is a positive axis with coordinates black at 0 to white at 100. \na\\*-axis is present along horizontal from left to right in the range of -128 to 127, +a\\* is the red axis, and -a\\* is the green axis.\nb\\*-axis runs along top to down in the range of -128 to 127, +b\\* axis is the yellow axis, and -b\\* axis is the blue axis.\n\n![Lab color space:=:40:=:Lab color space$$$https://www.xrite.com/blog/lab-color-space](color-theory/lab-color-space.jpg)\n\nAt the center, colors are achromatic colors, and saturation increases moving towards the circumference.\n\n### YUV and YCbCr\n\n[YUV](https://en.wikipedia.org/wiki/YUV) and [YCbCr](https://en.wikipedia.org/wiki/YCbCr) are a family of color spaces used to encode color data. In both models, the Y component refers to luminance but practically Y'UV and Y'CbCr are used. Y' component is luma which is scaled in the range of 0-100. The other two components are chrominance components derived by the difference of Y' on blue and red values.\n\nYUV, historically used for transmitting video data for analog devices. In the olden days, as there was a need to support both black and white display and color displays, a conversion has be to applied for RGB data to transmit signals without disturbing black-and-white channels. As the black-and-white image is the same as the luminance channel, YUV was developed to pass chrominance channels along with luminance. Later, YCbCr was developed to store, compress and encode digital photographs. YUV is for analog TVs and YCbCr is for digital TVs. \n\nUsing [chroma subsampling](https://www.matrox.com/en/video/media/guides-articles/introduction-color-spaces-video), image data can be transmitted and stored at a low-bit rate for chrominance channels UV and CbCr, because human eyes are tolerant for perceptually equal colors. This made transmitting or storing image data in [Y'UV or Y'CbCr](https://docs.microsoft.com/en-us/windows/win32/medfound/about-yuv-video) requires less space: a high bit-rate luma channel and low bit-rate chrominance channels.\n\nConversion from **RGB** to **Y'UV** is computed as follows:\n$$\nY' = W_{R}R + W_{G}G + W_{B}B\n$$\n$$\nY' = 0.299R + 0.587G + 0.114B\n$$\n$$\nU = U_{max}\\frac{B - Y'}{1 - W_B}\n$$\n$$\nV = V_{max}\\frac{R - Y'}{1 - W_R}\n$$\n\nWhere $W_R$, $W_G$, and $W_B$ are relative ratios of non-linear gamma-corrected RGB values. $U_{max}$ and $V_{max}$ are maximum values of the numerical range selected. For PAL and NTSC, these values were $U_{max} = 0.436$ and $V_{max} = 0.615$.\n\nSimilarly, **RGB** to **Y'CbCr** is computed as\n$$\nY' = K_{R}R + K_{G}G + K_{B}B\n$$\n$$\nY' = 0.299R + 0.587G + 0.114B\n$$\n$$\nC_b = \\frac{1}{2}\\frac{B - Y'}{1 - K_B}\n$$\n$$\nC_r = \\frac{1}{2}\\frac{R - Y'}{1 - K_R}\n$$\n\nWhere $K_R$, $K_G$, and $K_B$ are relative ratios of non-linear gamma-corrected RGB values and satisfies $K_R + K_G + K_R = 1$.\n\n---\n\n## Device-dependent and device-independent color spaces\n\n**Device-dependent** color models mean they depend on the display system subset of colors or reference color space. This model explains the physical device output rather than human color vision. Coordinates used to display colors in device-dependent models change when the display system changes its light source. RGB, CMY, HSV, and HSL are device-dependent color models.\n\n**Device-independent** color spaces are universal references and coordinates used to specify colors will produce the same color in all conditions because they define color output based on human color vision. These are used to convert device-dependent color spaces across display devices. CIELAB, CIELUV, YCbCr, and YUV are device-independent color spaces."},{"metadata":{"title":"Color Science","description":"Understanding the concept of Color from human eye's perception to digital world representation.","imgName":"color-science/color-science.jpg","date":"Aug 28, 2021","tags":["image-processing"],"keywords":["color-matching","color","chromaticity-diagram","cie","graphic-design"],"id":"color-science"},"content":"\n![Color Science](color-science/color-science.jpg)\n\n# Color Science\n\nColor is an important element that exists in nature. Everything we see or feel through the eyes is all about colors. It is necessary to understand the concept of color in domains like image processing, film making, and digital photography, where color is the primary element.\n\nFrom Space exploration to Film making, Air force to Archeology, color science is applied everywhere that uses colors to gather data. For example Hubble telescope uses image processing techniques like **broad-band** and **narrow-band** filtering to color map planets, nebula, and galaxies based on the gases and their interactions like in \"The Pillars of Creation\".\n\n![Pillars of Creation:=:40:=:The Pillars of Creation (NASA)$$$https://www.nasa.gov/image-feature/the-pillars-of-creation](color-science/pillars-of-creation.jpg)\n\nIn this article, we discuss color, the evolution of color understanding, and numerical representation of color in the digital world.\n\n---\n\n## Color and Human Vision\n\nWhen we talk about colors, colors are represented in a way human eyes perceive. Because different species see things in different colors, and they can also see what humans cannot see like Snakes and Bats can detect infrared radiation which humans couldn't. So we generally restrict colors to human vision.\n\nColor is an illusion that our brain creates when a light beam reflects off an object/emits from an object and reaches our eyes. When light strikes the surface of an object, some light will be absorbed and some will be reflected. That reflected light with different wavelengths reaches our eyes and we perceive them as different colors.\n\nIssac Newton described the color as a quality of light. And the light which is an electromagnetic wave is classified into different segments with certain frequencies and wavelength ranges. The visible light spectrum is the segment of the electromagnetic spectrum that human eyes can only perceive. The visible light wavelength range is ~380 to ~780 nanometers. By deflection of light through a prism, Newton assigned different colors to different wavelengths in the visible spectrum which we generally see when a rainbow appears (VIBGYOR).\n\n![Visible Spectrum:=:55:=:Visible Light Spectrum$$$https://en.wikipedia.org/wiki/Electromagnetic_radiation](color-science/visible-spectrum.jpg)\n\nThe retina in our eye is responsible for vision. The retina contains photoreceptor cells that convert light signals to neural signals and send those signals back to the brain through nerves. And then, the brain intercepts these signals to colors. Rods and Cones in the retina are two types of photoreceptors that are responsible for our vision in dark and bright conditions. Rods work at a low level of light and our vision is in grayscale. Rods don't provide any color vision. At night as there is a low level of light we can see the objects in combinations of white and black (grayscale). Cones work in bright light and provides color vision. \n\n![Retina:=:70:=:Light capture by Rods and Cones in Retina$$$https://www.xrite.com/blog/color-perception-part-3](color-science/retina-rods-cones.jpg)\n\n### Triochromatic theory\n\nIn the 1800s, Thomas Young stated that the human eye consists of three different types of color receptors more likely red, green, and blue, and mixing these colors create other colors.\n\nThere are three types of cones called short (S), medium (M), and long (L) which are sensitive to different wavelength ranges of spectral distribution and detect Blue, Green, and Red respectively.\n\n![Normalized Cone Responsivity:=:45:=:Normalized Responsivity$$$https://en.wikipedia.org/wiki/Cone_cell^^^ of S, M and L cones](color-science/normalized-cone-responsivity.jpg)\n\nThese S, M, and L cones detect Blue, Green, and Red colors respectively and other colors are perceived by overlapping of different stimulations of these cones. The brain then integrates these cone signals and detects millions of colors. For example, Yellow color is a proportion of Green and Red cones and no or less effect of Blue cone. These three colors RGB (Red, Green, Blue) are primary colors and any color can be produced with the combination of these primitive colors.\n\n![Retinal Response:=:40:=:Retinal Response$$$https://askabiologist.asu.edu/rods-and-cones^^^ of rods and cones](color-science/retinal-response.jpg)\n\nIf we mix all RGB colors at a high-intensity level we get White color, and if RGB colors with 0 intensity level produce Black Color.\n\n### Opponent process theory:=:opponent-process-theory\n\nAfter cones converting physical (light) signals to neural signals, these neural signals reach the brain through nerves. Here, cells changes behavior and responds in the opponent manner for colors. The photoreceptor cells are in inter-connection with each other cell and give positive or negative responses for incoming color signals. Some cells fire positive signals when seeing red color, and activate negative signals for green color. These opposite responses don't happen at the same time in a cell. The opponent-process theory states that color perception is controlled by three opponent color systems: red-green, blue-yellow, and white-black (according to recent studies, these pairs are blue-yellow, red-cyan, and green-magenta). These opponent colors don't perceive as together because cells can only fire one of the colors in a pair i.e. there is no \"bluish-yellow\" or \"greenish-red\".\n\n![Opponent Process:=:60:=:Opponent Process$$$https://en.wikipedia.org/wiki/Opponent_process](color-science/opponent-process-theory.jpg)\n\nThese trichromatic and opponent-process theories give an idea about how our brain receives and processes light signals into colors.\n\n## The Color of an object\n\nWhen a light beam hits the surface of an object, it absorbs some wavelengths and reflects a particular wavelength of light. An object looking Pink absorbs all wavelengths of light except some portion of Red and Blue. And our eyes receive those Red and Blue colors by cones and intercept as pink by stimulating the Red and Blue cones. Paints on walls are made to absorb all of the wavelengths except the color of their appearance. \n\n### Secondary colors\n\nIf we mix two primary colors at equal intensities and another one is being kept at a 0 level, we get secondary colors.\n- Cyan (Blue + Green)\n- Magenta (Red + Blue)\n- Yellow (Green + Red). \n\nThese Cyan (C), Magenta (M), and Yellow (Y) colors are called secondary colors (CMY) as they are derived from primary ones (RGB).\n\nC, M, and Y are also complementary colors to R, G, and B as synthesize of C, M and Y don't contain R, G, and B colors respectively. This means when an object is illuminated with RGB colors, the object absorbs at least one primary color and reflects the other two primary colors. An object looking Cyan would absorb Red but reflects Green and Blue (G + B = C). Mixing secondary colors produces RGB colors.\n- M + Y = R\n- Y + C = G\n- C + M = B\n\n### Additive and Subtractive color mixing:=:additve-subtractive-color-mixing\n\nThe object appears in different colors if the various amount of RGB light emitted from it. It appears black when no percentage of RGB is emitted and if all are emitted at the highest intensity, it appears as white. Thus adding different RGB percentages produce different colors. This process of synthesizing colors by emitting RGB colors from black (when no light is produced) is called **Additive** color model. We start from black and reach white. Display monitors and screens we see around are based on an Additive color model. They produce colors by varying RGB color intensities.\n\nWhat if an object instead of emitting it reflects certain wavelengths of light by absorbing other wavelengths. This is how we naturally see an object and its appearance. An object absorbs some light and reflects other visible spectrum wavelengths that are perceived as color by our eyes. If an object absorbs cyan color, then it reflects red. Because \n$$\n\\small{White - Cyan = (R + G + B) - (G + B) = R}\n$$\nif we subtract cyan from white it produces a red color. \n\n![Additive and Subtractive Colors:=:40](color-science/additive-subtractive-colors.jpeg)\n\nHere subtracting means mixing colors as an object absorbs colors and then reflects. Thus mixing CMY colors with a white color produces different colors. This process of synthesizing colors from adding CMY mixtures to white is called **Subtractive** color model. We start from white to black color. Printing and painting involve this color synthesis to generate different colors on white paper or canvas. As mixing of CMY at the highest intensity produces brown color, printers also use black (K) color to generate shades of the black, and the resultant color group is called as CMYK color model.\n\n---\n\n## Color matching\n\nColor matching is representing and reproducing any color wavelength using primary monochromatic wavelengths. Using different intensities of primary colors, the target color wavelength is produced.\n\n### Grassmann's laws of additive color mixture\n\nIn 1953, Grassmann recognized that any color can be matched with a linear combination of three primary colors. Grassmann's laws describe the relations between primary colors to match any color by additive color mixture. The following Grassmann's laws are fundamental for color mixing,\n\n- If two colors (X and Y) are the same, then mixing X and Y with the third color Z would still look like same. \n$$\n\\footnotesize{If \\space X = Y, \\space then \\space X + Z = Y + Z}\n$$\n\n- Any color C can be produced by a linear combination of three primary colors but no primary color is matched by a combination of the other two. \n$$\n\\footnotesize{C = xX + yY + zZ}\n$$\nwhere (x, y, z) are portions of primary colors (X, Y, Z) required to match color C.\n\n- Two colors C1 and C2, if mixed to form another color C3, then C3 can be matched by a linear combination of mixtures of primary colors that are used to produce C1 and color C3. \n$$\n\\footnotesize{C3 = C1 + C2 = (xX1 + yY1 + zZ1) + (xX2 + yY2 + zZ2)}\n$$\n\n- Colors that are produced by mixing primary colors have constant luminance. This is not true at various lighting conditions like in photopic (daylight) vision, objects appear in different colors, but in scotopic (night) vision, objects appear in grayscale.\n\n\n### Human tristimulus response\n\nIn the 1860s, James Maxwell stated that using RGB primary colors, all other colors can be generated but it is not possible to generate all colors only by addition and requires subtraction also to match certain colors. This is called the human tristimulus response. \n\n### 2\u0026deg Standard Observer color-matching experiment\n\nIn the late 1920s, based on the works of Newton, Grassmann, and Maxwell, David Wright and John Guild independently conducted experiments to quantify the color reception ability of a normal human observer. They believed that human color receptors are located within the 2\u0026deg arc of the fovea back from the retina, and asked standard observers or human volunteers to look through a hole that provides a 2\u0026deg field of view. They asked volunteers to match the target color by adjusting combinations of red, blue, and green colors.\n\nAs not all colors could be matching using an additive color model of red, blue, and green, the target color is mixed with some portion of the primary color, and the other two primary colors are altered in portions to match the target colors.\n\nThe Commission International de lâEclairage (CIE), based on Wright-Guild's 2\u0026deg standard observer data, published RGB color matching functions to represent colors as a combination of three primary colors. This is also called **CIE standard 2\u0026deg observer**.\n\n![2\u0026deg and 10\u0026deg Standard Observer:=:40:=:2\u0026deg and 10\u0026deg standard observer view$$$https://support.hunterlab.com/hc/en-us/articles/203420099-CIE-Standard-Observers-and-calculation-of-CIE-X-Y-Z-color-values-AN-1002b](color-science/standard-observer.jpg)\n\n### 10\u0026deg Supplementary Standard Observer color-matching experiment\n\nIn the 1960s, researchers observed that cones present in the retina cover a larger field than the standard 2\u0026deg view. Three researchers, Stiles, Burch, and Speranskaya again repeated color matching experiments with a 10\u0026deg field view. They believed 10\u0026deg color matching experiments would cover more spectral response than 2\u0026deg. And it was right. In 1964, the CIE published 10\u0026deg Standard Observer based on a 10\u0026deg color-matching experiment. The 10\u0026deg standard observer is recommended than 2\u0026deg as it covers larger color representatives.\n\n## CIE 1924 $\\small{V(\\lambda)}$ Spectral Luminous Efficiency function\n\nHuman eyes perceive different wavelengths of the visible spectrum at different brightness levels for the same radiance energy. Sensitivity is zero at either end of the spectrum thus we receive 0 brightness and no color.\n\nThe luminous efficiency function describes the human eye's sensitivity for different wavelengths. The more sensitivity observed the more brightness the color is. Eyes are most sensitive at **555nm** at daylight (photopic) and **507nm** at night (scotopic). CIE $\\small{V(\\lambda)}$ luminosity curve tells the relative sensitivity of the human eye for different color wavelengths. The luminous efficiency function distinguishes the brightness level of two colors at equal luminous. We can derive relative brightness for different colors with $\\small{V(\\lambda)}$ function.\n\n![Luminous efficiency function:=:50:=:Photopic (black) and Scotopic (green) luminosity function$$$https://en.wikipedia.org/wiki/Luminous_efficiencG_function](color-science/luminosity-curve.jpg)\n\nFrom $\\small{V(\\lambda)}$ luminous efficiency function, we can observe that, for equal radiance energy, brightness order of RGB is **green\u003ered\u003eblue**. For two colors at **500nm** and **570nm** to look as equal brightness, the color at **500nm** should be more luminous than **570nm**. \n$\\small{V(\\lambda)}$ function is an approximation function and accurate in some cases (like color blind people).\n\n### Relative luminance of RGB primaries:=:relative-luminance\n\nThe above CIE RGB color matching functions are scaled in assumtion that all colors have same brightness. The $\\bar{r}$, $\\bar{g}$ and $\\bar{b}$ are normalized to have equal area under curve to yield $\\bar{r}(\\lambda) = \\bar{g}(\\lambda) = \\bar{b}(\\lambda) = 1$. The integrated area is assumed to be same that\n$$\n\\int \\bar{r}(\\lambda)d\\lambda = \\int \\bar{g}(\\lambda)d\\lambda = \\int \\bar{b}(\\lambda)d\\lambda = \\int V(\\lambda)d\\lambda\n$$\n\nSolving the above expression gives the relative luminanace ratios for **r : g : b = 1 : 4.5907 : 0.0601**. If we compare $V(\\lambda)$ luminous curve for **R = 700nm**, **G = 546.1nm** and **G = 435.8nm**, (r, g, b) luminance ratios are approximately matches.\n\nIf ratios are normalized such that sum of ratios equals to 1, then **r : g : b = 0.2126 : 0.7152 : 0.0722**.\n\nTo match any target color, RGB colors are mixed in portions obtained from the CIE RGB color-matching function, and then those resultant RGB values should multiply by relative luminance ratios to get the target color with exact brightness.\n\n## CIE 1931 RGB color matching functions\n\nThe **Color matching functions** are mathematical estimation of color response of each primary color relative to human observer in 2\u0026deg view field. Color matching functions gives amount of primary color energy required to generate target color wavelength. CIE defined three color mathcing functions $\\small{\\bar{r}(\\lambda), \\space \\bar{g}(\\lambda) \\space and \\space \\bar{b}(\\lambda)}$ which are normalized weight factors.\n\n![CIE 1931 RGB color matching functions:=:50](color-science/cie-rgb-cmf.jpg)\n\nIn the above RGB cmf diagram, each color wave represents RGB spectral intensities at various wavelengths. The three primary colors have peak sensitivity at wavelengths **R = 700nm**, **G = 546.1nm** and **G = 435.8nm**. The distribution of spectral energy is normalized and adding all color matching functions equals 1. Negative values in the graph indicate primary colors have to be mixed with the target color before color matching. And $\\small{\\bar{r}(\\lambda)}$ slightly matches the $\\small{V(\\lambda)}$ luminous efficiency function.\n\n### RGB Tristimulus values\n\nThe **tristimulus values** are, in a color space, the amount of color proportions of primary colors are required in a trichromatic additive color model to produce a color.\n\nFor CIE 1931 RGB color space, the RGB tristimulus values for spectral distribution of color $\\small{S(\\lambda)}$ can be calculated as\n$$\n\\small{R = \\int S(\\lambda)\\bar{r}(\\lambda)d\\lambda \\hspace2ex\nG = \\int S(\\lambda)\\bar{g}(\\lambda)d\\lambda \\hspace2ex\nB = \\int S(\\lambda)\\bar{b}(\\lambda)d\\lambda}\n$$\n\nwhere $\\small{S(\\lambda)}$ is spectral intensity of a color.\n\nIt can also be expressed as, for a color $\\small{C}$,\n$$\n\\small{C = R\\bar{r}(\\lambda) + G\\bar{g}(\\lambda) + B\\bar{b}(\\lambda)}\n$$\n$$\n\\small{C = R\\bold{R} + G\\bold{G} + B\\bold{B}}\n$$\n\nwhere $\\small{R}$, $\\small{G}$ and $\\small{B}$ are tristimulus values, and scaled to unit length.\n\n## CIE XYZ color matching functions\n\nRGB color matching functions contain negative intensities in mathematical form but they are not practically suitable for the physical world. CIE then converted RGB color space to XYZ color space where XYZ are linear combinations of monochromatic colors RGB. The new XYZ color matching functions have only positive intensities. The derived XYZ parameters are imaginary and they roughly represent S, M, and L cones.\n\n![CIE XYZ color matching functions:=:60](color-science/cie-xyz-cmf.jpg)\n\n$\\small{\\bar{x}(\\lambda), \\bar{y}(\\lambda) \\space and \\space \\bar{z}(\\lambda)}$ are color matching functions. From above diagram, we can say Violet (around 450nm) color is a mixture of Red and Blue which is indeed true and this cannot be seen in RGB color matching function curves.\n\nAlso, distribution of $\\small{\\bar{y}(\\lambda)}$ is close to $\\small{V(\\lambda)}$ luminous efficiency function. So Y component also roughly describes the luminance of the color.\n\nXYZ is a linear combination of RGB colors. If RGB colors are vectors with unit length and act as vector basis, they form a three-dimensional vector space. And XYZ vectors form a new basis vector by a linear transformation **M** of RGB vector basis.\n\n$$\n\\small{\\begin{bmatrix}\nX \\\\\nY \\\\\nZ \\\\\n\\end{bmatrix} = M\n\\begin{bmatrix}\nR \u0026 G \u0026 B\n\\end{bmatrix}}\n$$\n$$\n\\small{\\begin{bmatrix}\nX \\\\\nY \\\\\nZ \\\\\n\\end{bmatrix} = \n\\begin{bmatrix}\nR_x \u0026 R_y \u0026 R_z \\\\\nG_x \u0026 G_y \u0026 G_z \\\\\nB_x \u0026 B_y \u0026 B_z\n\\end{bmatrix}\n\\begin{bmatrix}\nR \u0026 G \u0026 B\n\\end{bmatrix}}\n$$\n$$\n\\small{\\begin{bmatrix}\nX \\\\\nY \\\\\nZ \\\\\n\\end{bmatrix} = \\frac{1}{0.17}\n\\begin{bmatrix}\n0.49 \u0026 0.31 \u0026 0.20 \\\\\n0.17 \u0026 0.81 \u0026 0.01 \\\\\n0.00 \u0026 0.01 \u0026 0.99\n\\end{bmatrix}\n\\begin{bmatrix}\nR \u0026 G \u0026 B\n\\end{bmatrix}}\n$$\n\nwhere X, Y, and Z are tristimulus values defined as, for spectral color distribution $\\small{S(\\lambda)}$\n$$\n\\small{X = \\int S(\\lambda)\\bar{x}(\\lambda)d\\lambda \\hspace2ex\nY = \\int S(\\lambda)\\bar{y}(\\lambda)d\\lambda \\hspace2ex\nZ = \\int S(\\lambda)\\bar{z}(\\lambda)d\\lambda}\n$$\n\nFrom the above transformation matrix **M**, we can say Red and Green colors have zero or no impact on Z which can be confirmed from RGB color matching functions.\n\n---\n\n## CIE xy chromaticity diagram \u0026 CIE xyY color space\n\nImagine if XYZ tristimulus values are represented as unit scale vectors, they form a 3D vector space and contains all possible colors with RGB combinations in a cube. Now trace out the coordinates of XYZ for different wavelengths in the visible spectrum, the closed curve that is formed by joining all coordinates is called spectral locus.\n\n![CIE XYZ color space:=:60:=:CIE XYZ spectral locus$$$https://commons.wikimedia.org/wiki/File:3D_Graph_of_CIE_XYZ_Colorspace.png](color-science/cie-xyz-colorspace.jpg)\n\nThe above 3D XYZ color space contains colors with Hue, Saturation, and Intensity/Brightness. It requires three parameters (H, S, and V) to describe a color (each for hue, saturation, and intensity).\n\nIf (X, Y, Z) are projected to $\\small{X + Y + Z = 1}$ plane in XYZ vector space, then normalized representation of (X, Y, Z) is\n$$\n\\small{x = \\frac{X}{X + Y + Z} \\hspace2ex \ny = \\frac{Y}{X + Y + Z} \\hspace2ex\nz = \\frac{Z}{X + Y + Z}}\n$$\n\nsumming up the normalized x, y and z components equals to 1 i.e, $\\small{x + y + z = 1}$ and $\\small{x,y,z\\ge0}$\n\nThe planar projection of the above spectral locus to the plane $\\small{X + Y + Z = 1}$, then it forms a planar triangle.\n\n![CIE XYZ planar projection:=:35](color-science/spectral-locus-planar-projection.jpg)\n\n**Chromaticity** is a color property without intensity i.e color independent component of a color. Chromaticity is the quality of a color determined by its dominant wavelength and its purity (chroma/saturation). In chromaticity, only hue and saturation are used to describe the colors. That means light blue and dark blue have the same hue and saturation values, and same color matching functions.\n\nA chromaticity diagram is a representation of 3D XYZ color space in 2D space with only chromaticity values (hue and saturation). As $x + y + z =1$, any component can be derived from two other components. So z can be derived from x and y as\n$$\n\\small{x + y + z = 1}\n$$\n$$\n\\small{z = 1 - x - y}\n$$\n\nAny tristimulus value can be derived from other tristimulus values. With Y, X and Z are derived as \n$$\n\\small{X = \\frac{Y}{y}x}\n$$\n$$\n\\small{Z = \\frac{Y}{y}(1 - x - y)}\n$$\n\nIf the above spectral locus triangular plane in xyz-plane is projected onto xy-plane, a chromaticity diagram is obtained. And to construct the actual XYZ values, Y is stored along with xy. Together xyY forms the **CIE xyY** color space with xy as chromaticity coordinates and Y as a luminance value because we discussed earlier that the Y component roughly matches $\\small{V(\\lambda)}$.\n\nThe [RGB chromaticity diagram](https://en.wikipedia.org/wiki/Rg_chromaticity) could be constructed by following the same procedure as XYZ. Here **CIE rgG** color space is constructed by keeping rg chromaticity coordinates and G value for luminance.\n\n![CIE chromaticity diagram:=:50:=:CIE xyY chromaticity diagram](color-science/cie-chromaticity-diagram.jpg)\n\nThe horseshoe shape in the above diagram contains all colors of the projected planar triangle. The chromaticity diagram is a mathematical representation of the human eye's color perception. \n- The outer line of the spectral locus has colors with wavelengths distributed across in visible spectrum. Starting from violet to red and magenta line as a bridge between. These colors are hues or dominant wavelength colors which are seen in the rainbow.\n- The region inside the spectral locus contains all colors possible in XYZ space that are visible to our human eyes. These colors are saturated colors of hues or a mixture of monochromatic wavelengths.\n- A point (x, y) on the above graph matches a color in the xyY color space.\n- It can be observed that CMY (cyan, magenta, yellow) colors lie between (green and blue), (blue and red), and (red and green). CMY colors are present in complement/opposite to RGB.\n\n### Color gamut\n\n**Color gamut** describes a range of colors in the visible spectrum that are visible for human eyes. The color gamut of a device is that subset of color space that can be represented. color gamuts are generally a subset of the CIE chromaticity diagram with the center as a white point.\n\n![Color gamut:=:50:=:Different color gamuts in CIE xy chromaticity diagram$$$https://en.wikipedia.org/wiki/Gamut](color-science/color-gamut.jpg)\n\nColor gamuts are color spaces enclosed by a triangle with color coordinates of the monitor as red, green, and blue colors. A gamut is a three-dimensional color space with lightness being the third dimension perpendicular to the chromaticity diagram.\n\nCertain color gamuts are standardized by different institutions to reproduce the colors across different environments. The **sRGB** color gamut is the standard color subset used to display colors around the web.\n\nThe colors outside of the chromaticity diagram but inside a color gamut (like ProPhoto RGB) are called imaginary colors as they are not visible for human eyes and they look like normal visible colors. These colors can be detected using color measuring techniques but our eyes cannot differentiate those colors with normal visible colors.\n\n---\n\nOver time, different color spaces and techniques were developed to describe human color perception. **Colorimetry** and **Spectrophotometry** are two different methods to quantify the colors. CIE XYZ color spaces are also defined for the 10\u0026deg standard observer, and it is the standard color space being used in the modern digital world. In the fields like image processing and digital photography, it is necessary to have a good grasp of concepts like chromaticity diagram and color gamuts that are useful for methods like color constancy, color correction, and color grading. \n\nFor further study about colors, check out the topics like color tolerance, color difference, conversion of different color gamuts between display systems, and additional color spaces like CIE LAB.\n\n---\n\n### References\n- [How the CIE 1931 color matching functions were derived](https://silo.tips/download/how-the-cie-1931-color-matching-functions-were-derived-from-wright-guild-data)\n- https://scholar.harvard.edu/files/schwartz/files/lecture17-color.pdf\n- [CIE 1931 color space - Wikipedia](https://en.wikipedia.org/wiki/CIE_1931_color_space)\n- [CIE color space - Gernot Hoffmann](http://docs-hoffmann.de/ciexyz29082000.pdf)\n- https://engineering.purdue.edu/~bouman/ece637/notes/pdf/Tristimulus.pdf\n- http://graphics.stanford.edu/courses/cs148-10-summer/docs/02_light_color.pdf\n- http://cs.haifa.ac.il/hagit/courses/ist/Lectures/IST03_ColorXYZx4.pdf\n- http://www.cs.cmu.edu/afs/cs/academic/class/15462-s16/www/lec_slides/23_color.pdf\n- https://web.eecs.umich.edu/~sugih/courses/eecs487/lectures/22-Light+Color.pdf\n- [Light, Color and Color Space - Scratch Pixel](https://www.scratchapixel.com/lessons/digital-imaging/colors/color-space)\n- [Color Matching - Craig Blackwell](https://www.youtube.com/watch?v=82ItpxqPP4I)\n- [Visualizing the XYZ Color space](https://www.youtube.com/watch?v=x0-qoXOCOow)\n- [A Beginner's Guide to Colorimetry](https://medium.com/hipster-color-science/a-beginners-guide-to-colorimetry-401f1830b65a)\n- [Precise Color Communincation - Konica Minolta](https://www.konicaminolta.com/instruments/knowledge/color/index.html)\n- [Color Gamut](https://epxx.co/artigos/gamut_en.html)"},{"metadata":{"title":"Create a Notes App with Flutter","description":"Create a color-rich Note-taking app with Flutter.","imgName":"note-app-flutter/note-app-in-flutter.jpg","date":"Jun 15, 2021","tags":["flutter"],"keywords":["flutter","dart","android","note-app","note-taking","sqflite","sqlite"],"id":"create-a-notes-app-with-flutter"},"content":"\n![Create a Notes App with flutter](note-app-flutter/note-app-in-flutter.jpg)\n\n# Create a Note-taking App in Flutter\n\nFlutter is a declarative framework that requires programming in Dart. Flutter is suitable for creating simple apps like Note-taking, Event-registration, etc.\n\n\u003e Pre-requisites: Knowledge of basic Dart and Flutter. Read about [Flutter](https://flutter.dev/docs) and [Dart](https://dart.dev/guides).\n\nWith basic concepts like Widgets and Material design we can create simple apps very fast and easily in Flutter as in Flutter we can use tons of pre-designed widgets to create almost every popular design using in the modern design world.\n\nIn this tutorial, we discuss creating a simple note-taking app. The note-taking app we are going to create provides options like create, save, update and delete notes. \n\nOur note-taking app contains two screens \n- Home screen to display all saved notes\n- Notes edit screen to create new notes or edit saved notes\n\n## Create Flutter App\n\nBefore creating a Flutter app please make sure you have installed flutter-sdk and dart-sdk. If not follow the instructions to [install flutter](https://flutter.dev/docs/get-started/install).\n\nCreate a raw flutter app from the terminal. Run the following command and pass any name (to join more than single sting use only underscore)\n\n```bash\nflutter create notes_app\n```\n\nGo to root directory of **notes_app** and locate **main.dart** in **lib** folder. This is where our app starts execution by calling the main() function. You can find some code here which displays the welcome screen.\n\nNow to see the app in an emulator or on a physical device run the below command.\n\n```bash\ncd notes_app/\nflutter run\n```\n\nFor the initial run, it takes some time to install the app on the device, and later builds will be fast. If you encounter any error run _flutter doctor -v_ for additional information and make sure all necessary items are checked.\n\n---\n\n## What a Note should like and contain?\n\nA simple note must have a title and the content which can be edited as many times as possible. We can also add color to note for look and feel. \n\nTo store notes we use [Sqflite](https://pub.dev/packages/sqflite) (a plugin to mimic SQL database in Flutter). Each note can be stored as a single row in the database with fields id, title, content, color. \n\nCreate a file **note.dart** inside **lib/models**. Add a class **Note** to store note as an object which can be converted later as a Map object to store in the database.\n\n```dart:models/note.dart\nclass Note {\n\tint id;\n\tString title;\n\tString content;\n\tString noteColor;\n\n\tNote({\n\t\tthis.id = null, \n\t\tthis.title = \"Note\", \n\t\tthis.content = \"Text\", \n\t\tthis.noteColor = 'red'\n\t});\n\n\tMap\u003cString, dynamic\u003e toMap() {\n\t\tMap\u003cString, dynamic\u003e data = Map\u003cString, dynamic\u003e();\n\t\tif (id != null) {\n\t\t\tdata['id'] = id;\n\t\t}\n\t\tdata['title'] = title;\n\t\tdata['content'] = content;\n\t\tdata['noteColor'] = noteColor;\n\t\treturn data;\n\t}\n\n\t@override toString() {\n\t\treturn {\n\t\t\t'id': id,\n\t\t\t'title': title,\n\t\t\t'content': content,\n\t\t\t'noteColor': noteColor,\n\t\t}.toString();\n\t}\n}\n```\n\nThis Note class has attributes\n- id (primary key) - an identifier to store unique note objects in the database\n- title - the title of the note\n- content - content of the note\n- noteColor - the color of the note\n\n**toMap()** returns note as an object to store in the database.\n\nFor note colors, add another file called **theme/note_colors.dart** inside **lib/theme**.\n```dart:theme/note_colors.dart\nconst NoteColors = {\n\t'red': {'l': 0xFFFFCDD2,'b': 0xFFE57373},\n\t'pink': {'l': 0xFFF8BBD0, 'b': 0xFFF06292},\n\t'purple': {'l': 0xFFE1BEE7, 'b': 0xFFBA68C8},\n\t'deepPurple': {'l': 0xFFD1C4E9, 'b': 0xFF9575CD},\n\t'indigo': {'l': 0xFFC5CAE9, 'b': 0xFF7986CB},\n\t'blue': {'l': 0xFFBBDEFB, 'b': 0xFF64B5F6},\n\t'lightBlue': {'l': 0xFFB3E5FC, 'b': 0xFF4FC3F7},\n\t'cyan': {'l': 0xFFB2EBF2, 'b': 0xFF4DD0E1},\n\t'teal': {'l': 0xFFB2DFDB, 'b': 0xFF4DB6AC},\n\t'green': {'l': 0xFFC8E6C9, 'b': 0xFF81C784},\n\t'lightGreen': {'l': 0xFFDCEDC8, 'b': 0xFFAED581},\n\t'lime': {'l': 0xFFF0F4C3, 'b': 0xFFDCE775},\n\t'yellow': {'l': 0xFFFFF9C4, 'b': 0xFFFFF176},\n\t'amber': {'l': 0xFFFFECB3, 'b': 0xFFFFD54F},\n\t'orange': {'l': 0xFFFFE0B2, 'b': 0xFFFFB74D},\n\t'deepOrange': {'l': 0xFFFFCCBC, 'b': 0xFFFF8A65},\n\t'brown': {'l': 0xFFD7CCCB, 'b': 0xFFA1887F},\n\t'blueGray': {'l': 0xFFCFD8DC, 'b': 0xFF90A4AE},\n};\n```\n\nEach color name ('k') is a key and each key ('k') has two colors 'l' and 'b', where 'l' is a light color and 'b' is the bright color of this 'k' color. The light and bright colors are used to display a note in the UI which we discuss later. 'k' is the color name we store in the database.\n\n---\n\n## Store notes in the database\n\nNow to store notes on the database we use **sqflite** plugin. Install **sqflite** by adding dependency in *pubspec.yaml*.\n\n```bash\ndependencies:\n  flutter:\n    sdk: flutter\n  sqflite: ^1.3.0\n```\n\nNow in terminal run *flutter pub get* to install or update dependencies in *pubspec.yaml*.\n\nTo handle database operations we write different functions for different operations like read, write, update and delete. Create **notes_database.dart** inside **models** and add a class to handle different operations\n\n```dart:models/notes_database.dart\nimport 'package:sqflite/sqflite.dart';\n\nimport 'note.dart';\n\nclass NotesDatabase {\n\tstatic final _name = \"NotesDatabase.db\";\n\tstatic final _version = 1;\n\n\tDatabase database;\n\tstatic final tableName = 'notes';\n\n\tinitDatabase() async {\n\t\tdatabase = await openDatabase(\n\t\t\t_name,\n\t\t\tversion: _version,\n\t\t\tonCreate: (Database db, int version) async {\n\t\t\t\tawait db.execute(\n\t\t\t\t\t'''CREATE TABLE $tableName (\n\t\t\t\t\tid INTEGER PRIMARY KEY AUTOINCREMENT,\n\t\t\t\t\ttitle TEXT,\n\t\t\t\t\tcontent TEXT,\n\t\t\t\t\tnoteColor TEXT\n\t\t\t\t\t)'''\n\t\t\t\t);\n\t\t\t}\n\t\t);\n\t}\n\n\tFuture\u003cint\u003e insertNote(Note note) async {\n\t\treturn await database.insert(tableName, \n\t\t\tnote.toMap(), \n\t\t\tconflictAlgorithm: ConflictAlgorithm.replace\n\t\t);\n\t}\n\n\tFuture\u003cint\u003e updateNote(Note note) async {\n\t\treturn await database.update(tableName, note.toMap(),\n\t\t\twhere: 'id = ?', \n\t\t\twhereArgs: [note.id],\n\t\t\tconflictAlgorithm: ConflictAlgorithm.replace\n\t\t);\n\t}\n\n\tFuture\u003cList\u003cMap\u003cString, dynamic\u003e\u003e\u003e getAllNotes() async {\n\t\treturn await database.query(tableName);\n\t}\n\n\tFuture\u003cMap\u003cString, dynamic\u003e\u003e getNotes(int id) async {\n\t\tvar result = await database.query(tableName,\n\t\t\twhere: 'id = ?',\n\t\t\twhereArgs: [id]\n\t\t);\n\n\t\tif (result.length \u003e 0) {\n\t\t\treturn result.first;\n\t\t}\n\n\t\treturn null;\n\t}\n\n\tFuture\u003cint\u003e deleteNote(int id) async {\n\t\treturn await database.delete(tableName,\n\t\t\twhere: 'id = ?',\n\t\t\twhereArgs: [id]\n\t\t);\n\t}\n\n\tcloseDatabase() async {\n\t\tawait database.close();\n\t}\n}\n```\n\nFirst, we need to create a table in the database with some schema. Inside **initDatabase()**, we are calling **openDatabase()** to create database and table or open existing database and table by passing parameters **_name** (name of the database) and **_version** where **_name = NotesDatabse.db** is the name of the database and we can maintain different versions of the database through **_version**. \n\nIf there is no database with a specified **name**, **onCreate** callback is called to create a database with table and schema. Above we create a table with **tableName = notes** and initial schema with required fields like id, title, content, and noteColor to store a note object. \n\n**openDatabase()** is an async operation and returns **Database** object reference which points to the created/existed database. We store this reference as **database** of type class **Database**.\n\nOther functions **insertNote**, **updateNote**, **getNotes** and **deleteNotes** handles different database operations. Read more about [how to perform different operations in sqflite](https://github.com/tekartik/sqflite/blob/master/sqflite/doc/how_to.md).\n\nAs we cannot store Note as a class object we convert Note object members to a Map object by calling Note.toMap() which returns a Map object which sqflite map fields and values to store in the database. And Sqflite returns data as Map objects the way we pass it to insert rows in the database.\n\nWe have added logic to maintain notes in the database. But we have not done anything in UI to interact for maintaining notes. \n\n## Add Home Screen\n\nNow create a file called **home.dart** in **lib/screens**. This **home.dart** serves as the Home screen of our app. Add following code to **home.dart**\n\n```dart:screens/home.dart\nimport 'package:flutter/material.dart';\n\nconst c1 = 0xFFFDFFFC, c2 = 0xFFFF595E, c3 = 0xFF374B4A, c4 = 0xFF00B1CC, c5 = 0xFFFFD65C, c6 = 0xFFB9CACA,\n\tc7 = 0x80374B4A, c8 = 0x3300B1CC, c9 = 0xCCFF595E;\n\n// Home Screen\nclass Home extends StatefulWidget{\n\t@override\n\t_Home createState() =\u003e _Home();\n}\n\nclass _Home extends State\u003cHome\u003e {\n\t@override\n\tWidget build(BuildContext context) {\n\t\treturn MaterialApp(\n\t\t\ttitle: 'Super Note',\n\t\t\thome: Scaffold(\n\t\t\t\tbackgroundColor: Color(c6),\n\t\t\t\tappBar: AppBar(\n\t\t\t\t\tautomaticallyImplyLeading: false,\n\t\t\t\t\tbackgroundColor: const Color(c2),\n\t\t\t\t\tbrightness: Brightness.dark,\n\n\t\t\t\t\ttitle: Text(\n\t\t\t\t\t\t'Super Note',\n\t\t\t\t\t\tstyle: TextStyle(\n\t\t\t\t\t\t\tcolor: const Color(c5),\n\t\t\t\t\t\t),\n\t\t\t\t\t),\n\t\t\t\t),\n\n\t\t\t\t//Floating Button\n\t\t\t\tfloatingActionButton: FloatingActionButton(\n\t\t\t\t\tchild: const Icon(\n\t\t\t\t\t\tIcons.add,\n\t\t\t\t\t\tcolor: const Color(c5),\n\t\t\t\t\t),\n\t\t\t\t\ttooltip: 'New Notes',\n\t\t\t\t\tbackgroundColor: const Color(c4),\n\t\t\t\t\tonPressed: () =\u003e {},\n\t\t\t\t),\n\t\t\t),\n\t\t);\n\t}\n}\n```\n\nThere are some color constants defined at the top which will be used across the app. The color format in Flutter is different from normal Hex. In normal Hex format, we provide opacity at last but in Flutter we have to provide opacity at first.\n\nHere we are creating a Home widget as **StatefulWidget** keeping in mind that we need to maintain the state. Every custom widget must override **build** method and return a widget. **MaterialApp** widget gives child widgets material look and we must declare required attributes. **Scaffold** widget is a common material design concept that provides appbar, floating button, drawer, body, etc.  \n\nThe Home screen displays all notes stored in the database. We discuss later displaying notes in the Home screen after creating notes in the Edit screen.\n\nTo display our Home screen as default screen in our app call **Home()** widget inside **MyApp** in **main.dart**\n\n```dart:main.dart\nimport 'package:flutter/material.dart';\n\nimport './screens/home.dart';\n\nvoid main() =\u003e runApp(MyApp());\n\nclass MyApp extends StatelessWidget {\n  @override\n  Widget build(BuildContext context) {\n    return MaterialApp(\n      home: Home(),\n    );\n  }\n}\n```\n\nTo see the changes in the app, in the flutter running environment press **r** to hot reload or **R** restart of the app.\n\n![Home Screen:=:30](note-app-flutter/notes-app-initial-home-screen.jpg)\n\nThe Floating action button at the bottom-right will take us to the Edit screen to create a new note. To add navigation from Home to Edit, first create a Edit Screen Widget in **notes_edit.dart** inside **lib/screens**. For now, add a simple UI for the Edit screen like below because we just need a widget to route from Home to Edit screen.\n\n```dart:screens/notes_edit.dart\nimport 'package:flutter/material.dart';\n\nconst c1 = 0xFFFDFFFC, c2 = 0xFFFF595E, c3 = 0xFF374B4A, c4 = 0xFF00B1CC, c5 = 0xFFFFD65C, c6 = 0xFFB9CACA,\n\t\t\tc7 = 0x80374B4A;\n\nclass NotesEdit extends StatefulWidget {\n\t_NotesEdit createState() =\u003e _NotesEdit();\n}\n\nclass _NotesEdit extends State\u003cNotesEdit\u003e {\n\t@override\n\tWidget build(BuildContext context) {\n\t\treturn MaterialApp(\n\t\t\ttitle: 'Edit Screen',\n\t\t\thome: Text(\n\t\t\t\t'Edit'\n\t\t\t),\n\t\t);\n\t}\n}\n```\n\n**NotesEdit** widget is the main widget for the Edit screen. We call this widget in navigation.\n\n### Navigation from Home to Edit\n\nAdd navigation from Home to Edit when pressed floating-action-buttton. Call **Navigation.push()** for the **EditNotes** widget. In **home.dart** add navigation in **onPressed()** event of floating-action-button.\n\n```dart\nimport './notes_edit.dart';\n```\n\n```dart\n//Floating Button\nfloatingActionButton: FloatingActionButton(\n\tchild: const Icon(\n\t\tIcons.add,\n\t\tcolor: const Color(c5),\n\t),\n\ttooltip: 'New Notes',\n\tbackgroundColor: const Color(c4),\n\t// Go to Edit screen\n\tonPressed: () {\n\t  Navigator.push(\n\t  \tcontext,     \n\t    MaterialPageRoute(builder: (context) =\u003e NotesEdit()),\n\t  );\n\t}\n),\n```\n\n---\n\n## Change Edit Screen\n\nChange Edit screen UI for creating a new note.\n\n```dart:screens/notes_edit.dart\nimport 'package:flutter/material.dart';\n\nimport '../models/note.dart';\nimport '../models/notes_database.dart';\nimport '../theme/note_colors.dart';\n\nconst c1 = 0xFFFDFFFC, c2 = 0xFFFF595E, c3 = 0xFF374B4A, c4 = 0xFF00B1CC, c5 = 0xFFFFD65C, c6 = 0xFFB9CACA,\n\tc7 = 0x80374B4A;\n\nclass NotesEdit extends StatefulWidget {\n\t_NotesEdit createState() =\u003e _NotesEdit();\n}\n\nclass _NotesEdit extends State\u003cNotesEdit\u003e {\n\tString noteTitle = '';\n\tString noteContent = '';\n\tString noteColor = 'red';\n\n\tTextEditingController _titleTextController = TextEditingController();\n\tTextEditingController _contentTextController = TextEditingController();\n\n\tvoid handleTitleTextChange() {\n\t\tsetState(() {\n\t\t\tnoteTitle = _titleTextController.text.trim();\n\t\t});\n\t}\n\n\tvoid handleNoteTextChange() {\n\t\tsetState(() {\n\t\t\tnoteContent = _contentTextController.text.trim();\n\t\t});\n\t}\n\n\t@override\n\tvoid initState() {\n\t\tsuper.initState();\n\t\t_titleTextController.addListener(handleTitleTextChange);\n\t\t_contentTextController.addListener(handleNoteTextChange);\n\t}\n\n\t@override\n\tvoid dispose() {\n\t\t_titleTextController.dispose();\n\t\t_contentTextController.dispose();\n\t\tsuper.dispose();\n\t}\n\n\t@override\n\tWidget build(BuildContext context) {\n\t\treturn Scaffold(\n\t\t\tbackgroundColor: Color(NoteColors[this.noteColor]['l']),\n\t\t\tappBar: AppBar(\n\t\t\t\tbackgroundColor: Color(NoteColors[this.noteColor]['b']),\n\n\t\t\t\tleading: IconButton(\n\t\t\t\t\ticon: const Icon(\n\t\t\t\t\t\tIcons.arrow_back,\n\t\t\t\t\t\tcolor: const Color(c1),\n\t\t\t\t\t),\n\t\t\t\t\ttooltip: 'Back',\n\t\t\t\t\tonPressed: () =\u003e {},\n\t\t\t\t),\n\n\t\t\t\ttitle: NoteTitleEntry(_titleTextController),\n\t\t\t),\n\n\t\t\tbody: NoteEntry(_contentTextController),\n\t\t);\n\t}\n}\n```\n\nIn the above **NotesEdit** widget, the state variables **noteTitle**, **noteContent** and **noteColor** are initialized to default values for now. **noteTitel** is to store title of the note, **noteContent** is to store note content and**noteColor** is color of the color, light and bright colors of the **noteColor** are used as **backgroundColor** for **appBar** and **Scaffold** respectively. \n\nAlso there are two **TextEditingController** defined which are used to controll **TextField** values for **noteTitle** and **noteContent**. These two text controller are attached with listeners in **iniitState()**. These listeneres listen to changes and updates text values in state. **_titleTextController** handles and updates text value for **noteTitle** and **_contentTextController** handles **noteContent**.\n\nThe **title** of the **appBar** is set to a widget **NoteTitleEntry** which handles displaying and editing of the title.\n\n```dart\nclass NoteTitleEntry extends StatelessWidget {\n\tfinal _textFieldController;\n\n\tNoteTitleEntry(this._textFieldController);\n\n\t@override\n\tWidget build(BuildContext context) {\n\t\treturn TextField(\n\t\t\tcontroller: _textFieldController,\n\t\t\tdecoration: InputDecoration(\n\t\t\t\tborder: InputBorder.none,\n\t\t\t\tfocusedBorder: InputBorder.none,\n\t\t\t\tenabledBorder: InputBorder.none,\n\t\t\t\terrorBorder: InputBorder.none,\n\t\t\t\tdisabledBorder: InputBorder.none,\n\t\t\t\tcontentPadding: EdgeInsets.all(0),\n\t\t\t\tcounter: null,\n\t\t\t\tcounterText: \"\",\n\t\t\t\thintText: 'Title',\n\t\t\t\thintStyle: TextStyle(\n\t\t\t\t\tfontSize: 21,\n\t\t\t\t\tfontWeight: FontWeight.bold,\n\t\t\t\t\theight: 1.5,\n\t\t\t\t),\n\t\t\t),\n\t\t\tmaxLength: 31,\n\t\t\tmaxLines: 1,\n\t\t\tstyle: TextStyle(\n\t\t\t\tfontSize: 21,\n\t\t\t\tfontWeight: FontWeight.bold,\n\t\t\t\theight: 1.5,\n\t\t\t\tcolor: Color(c1),\n\t\t\t),\n\t\t\ttextCapitalization: TextCapitalization.words,\n\t\t);\n\t}\t\n}\n```\n\nIn the **TextField**, the controller is set to **_textFieldController** which is passed from parent widget ** as **_titleTextController**. \n\nSimilarly, content of the notes is handled by another widget **NoteEntry**.\n\n```dart\nclass NoteEntry extends StatelessWidget {\n\tfinal _textFieldController;\n\n\tNoteEntry(this._textFieldController);\n\n\t@override\n\tWidget build(BuildContext context) {\n\t\treturn Container(\n\t\t\theight: MediaQuery.of(context).size.height,\n\t\t\tpadding: EdgeInsets.symmetric(horizontal: 12, vertical: 8),\n\t\t\tchild: TextField(\n\t\t\t\tcontroller: _textFieldController,\n\t\t\t\tmaxLines: null,\n\t\t\t\ttextCapitalization: TextCapitalization.sentences,\n\t\t\t\tdecoration: null,\n\t\t\t\tstyle: TextStyle(\n\t\t\t\t\tfontSize: 19,\n\t\t\t\t\theight: 1.5,\n\t\t\t\t),\n\t\t\t),\n\t\t);\n\t}\n}\n```\n\nHere also controller of **TextField** is set to **_textFieldController** which is passed from parent wdiget as **_contentTextController**.\n\nAfter adding all these widgets, the Edit screen would look like\n\n![Edit screen:=:30](note-app-flutter/notes-app-initial-edit-screen.jpg)\n\n### Add a Color palette to select Note color\n\nWe will add a color palette to select note color and store the value in **noteColor**. For color palette, add an icon in **appBar** **actions** which on press shows a **Dialog** box with different colors.\n\nIn **NotesEdit** add color palette button\n\n```dart\nactions: [\n\tIconButton(\n\t\ticon: const Icon(\n\t\t\tIcons.color_lens,\n\t\t\tcolor: const Color(c1),\n\t\t),\n\t\ttooltip: 'Color Palette',\n\t\tonPressed: () =\u003e handleColor(context),\n\t),\n],\n```\n\nFor this button, **onPressed** event calls **handleColor()** function which shows a color palette and store selected value in **noteColor** variable. Define **handleColor()** inside **_NotesEdit**\n\n```dart\nvoid handleColor(currentContext) {\n\tshowDialog(\n\t\tcontext: currentContext,\n\t\tbuilder: (context) =\u003e ColorPalette(\n\t\t\tparentContext: currentContext,\n\t\t),\n\t).then((colorName) {\n\t\tif (colorName != null) {\n\t\t\tsetState(() {\n\t\t\t\tnoteColor = colorName;\n\t\t\t});\n\t\t}\n\t});\n}\n```\n\nThis **handleColor()** calls widget **ColorPalette** which is a **Dialog** box and returns selected color value. Add **ColorPalette** widget to show different colors and return selected color\n\n```dart\nclass ColorPalette extends StatelessWidget {\n\tfinal parentContext;\n\n\tconst ColorPalette({ \n\t\t@required this.parentContext,\n\t});\n\n\t@override\n\tWidget build(BuildContext context) {\n\t\treturn Dialog(\n\t\t\tbackgroundColor: Color(c1),\n\t\t\tclipBehavior: Clip.hardEdge,\n\t\t\tinsetPadding: EdgeInsets.all(MediaQuery.of(context).size.width * 0.03),\n\t\t\tshape: RoundedRectangleBorder(\n\t\t\t\tborderRadius: BorderRadius.circular(2),\n\t\t\t),\n\t\t\tchild: Container(\n\t\t\t\tpadding: EdgeInsets.all(8),\n\t\t\t\tchild: Wrap(\n\t\t\t\t\talignment: WrapAlignment.start,\n\t\t\t\t\tspacing: MediaQuery.of(context).size.width * 0.02,\n\t\t\t\t\trunSpacing: MediaQuery.of(context).size.width * 0.02,\n\t\t\t\t\tchildren: NoteColors.entries.map((entry) {\n\t\t\t\t\t\treturn GestureDetector(\n\t\t\t\t\t\t\tonTap: () =\u003e Navigator.of(context).pop(entry.key),\n\t\t\t\t\t\t\tchild: Container(\n\t\t\t\t\t\t\t\twidth: MediaQuery.of(context).size.width * 0.12,\n\t\t\t\t\t\t\t\theight: MediaQuery.of(context).size.width * 0.12,\n\t\t\t\t\t\t\t\tdecoration: BoxDecoration(\n\t\t\t\t\t\t\t\t\tborderRadius: BorderRadius.circular(MediaQuery.of(context).size.width * 0.06),\n\t\t\t\t\t\t\t\t\tcolor: Color(entry.value['b']),\n\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t),\n\t\t\t\t\t\t);\n\t\t\t\t\t}).toList(),\n\t\t\t\t),\n\t\t\t),\n\t\t);\n\t}\n}\n``` \n\nAs we already stored different colors in **NoteColors** Map object, we iterate this object and fill the color palette with bright colors.\n\n![Color Palette:=:60](note-app-flutter/notes-app-color-palette.jpg)\n\n### Save notes\n\nWe have everything to save notes in the database. We save a note in the database if **backButton** is pressed at the top. Now add a function to handle **backButton** **onPressed**.\n\n```dart\nvoid handleBackButton() async {\n\tif (noteTitle.length == 0) {\n\t\t// Go Back without saving\n\t\tif (noteContent.length == 0) {\n\t\t\tNavigator.pop(context);\n\t\t\treturn;\n\t\t}\n\t\telse {\n\t\t\tString title = noteContent.split('\\n')[0];\n\t\t\tif (title.length \u003e 31) {\n\t\t\t\ttitle = title.substring(0, 31);\n\t\t\t}\n\t\t\tsetState(() {\n\t\t\t\tnoteTitle = title;\n\t\t\t});\n\t\t}\n\t}\n\n\t// Save New note\n\tNote noteObj = Note(\n\t\ttitle: noteTitle, \n\t\tcontent: noteContent, \n\t\tnoteColor: noteColor\n\t);\n\ttry {\n\t\tawait _insertNote(noteObj);\n\t} catch (e) {\n\t\tprint('Error inserting row');\n\t} finally {\n\t\tNavigator.pop(context);\n\t\treturn;\n\t}\n}\n```\n\nThis function calls **_insertNote()** which saves the note object in the database.\n\n```dart\nFuture\u003cvoid\u003e _insertNote(Note note) async {\n  NotesDatabase notesDb = NotesDatabase();\n  await notesDb.initDatabase();\n  int result = await notesDb.insertNote(note);\n  await notesDb.closeDatabase();\n}\n``` \n\nWe have saved notes in the database, now in the Home screen, display the saved notes in list view.\n\n---\n\n## Show saved notes on the Home screen\n\nWe can retrieve saved notes from the database and we use that retrieved data to show a note as a list on the Home screen. As retrieving data from the database is an async task and we need to have data before building the Home widget, we use [FutureBuilder](https://api.flutter.dev/flutter/widgets/FutureBuilder-class.html).\n\n```dart\nFuture\u003cList\u003cMap\u003cString, dynamic\u003e\u003e\u003e readDatabase() async {\n\ttry {\n\t  NotesDatabase notesDb = NotesDatabase();\n\t  await notesDb.initDatabase();\n\t  List\u003cMap\u003e notesList = await notesDb.getAllNotes();\n\t  await notesDb.closeDatabase();\n\t  List\u003cMap\u003cString, dynamic\u003e\u003e notesData = List\u003cMap\u003cString, dynamic\u003e\u003e.from(notesList);\n\t \tnotesData.sort((a, b) =\u003e (a['title']).compareTo(b['title']));\n\t  return notesData;\n\t} catch(e) {\n\t\tprint('Error retrieving notes');\n\t\treturn [{}];\n\t}\n}\n```\n\nThis function reads all saved notes in the database and returns them as **Future** objects. We call this function in FutureBuilder and it builds the note list which displays each notes as a list.\n\nBefore that add necessary imports in **home.dart** to handle the database, to store note object and colors.\n\n```dart\nimport '../models/note.dart';\nimport '../models/notes_database.dart';\nimport '../theme/note_colors.dart';\n```\nStore read notes from database in state and define other state variables\n\n```dart\nList\u003cMap\u003cString, dynamic\u003e\u003e notesData;\nList\u003cint\u003e selectedNoteIds = [];\n```\n\n**notesData** stores all notes data read from database and **selectedNoteIds** will have a list of selected notes when a note is selected in Home.\n\n```dart\nbody: FutureBuilder(\n\tfuture: readDatabase(),\n\tbuilder: (context, snapshot) {\n\t\tif (snapshot.hasData) {\n\t\t\tnotesData = snapshot.data;\n\t\t\treturn Stack(\n\t\t\t\tchildren: \u003cWidget\u003e[\n\t\t\t\t\t// Display Notes\n\t\t\t\t\tAllNoteLists(\n\t\t\t\t\t\tsnapshot.data,\n\t\t\t\t\t\tthis.selectedNoteIds,\n\t\t\t\t\t\tafterNavigatorPop,\n\t\t\t\t\t\thandleNoteListLongPress,\n\t\t\t\t\t\thandleNoteListTapAfterSelect,\n\t\t\t\t\t),\n\t\t\t\t],\n\t\t\t);\n\t\t} else if (snapshot.hasError) {\n\t\t\tprint('Error reading database');\n\t\t} else {\n\t\t\treturn Center(\n\t\t\t\tchild: CircularProgressIndicator(\n\t\t\t\t\tbackgroundColor: Color(c3),\n\t\t\t\t),\n\t\t\t);\n\t\t}\n\t}\n),\n```\n\nHere before building the widget we read the data from the database and builds a list of note widgets to display on the Home screen by calling **AllNoteLists** widget. We also pass different callback functions to **AllNoteLists** to handles cases like the long selection of note, deselect a note, etc.\n\nDefine all these functions inside **_Home**\n\n```dart\n// Render the screen and update changes\nvoid afterNavigatorPop() {\n\tsetState(() {});\n}\n\n// Long Press handler to display bottom bar\nvoid handleNoteListLongPress(int id) {\n\tsetState(() {\n\t\tif (selectedNoteIds.contains(id) == false) {\n\t\t\tselectedNoteIds.add(id);\n\t\t}\n\t});\n}\n\n// Remove selection after long press\nvoid handleNoteListTapAfterSelect(int id) {\n\tsetState(() {\n\t\tif (selectedNoteIds.contains(id) == true) {\n\t\t\tselectedNoteIds.remove(id);\n\t\t}\n\t});\n}\n\n// Delete Note/Notes\nvoid handleDelete() async {\n\ttry {\n\t\tNotesDatabase notesDb = NotesDatabase();\n\t\tawait notesDb.initDatabase();\n\t\tfor (int id in selectedNoteIds) {\n\t\t\tint result = await notesDb.deleteNote(id);\n\t\t}\n\t\tawait notesDb.closeDatabase();\n\t} catch (e) {\n\n\t} finally {\n\t\tsetState(() {\n\t\t\tselectedNoteIds = [];\n\t\t});\n\t}\n}\n```\n\nDefine **AllNoteLists** widget which gets arguments from parent widget including note data and callback functions to handle\n\n```dart\n// Display all notes\nclass AllNoteLists extends StatelessWidget {\n\tfinal data;\n\tfinal selectedNoteIds;\n\tfinal afterNavigatorPop;\n\tfinal handleNoteListLongPress;\n\tfinal handleNoteListTapAfterSelect;\n\n\tAllNoteLists(\n\t\tthis.data, \n\t\tthis.selectedNoteIds,\n\t\tthis.afterNavigatorPop,\n\t\tthis.handleNoteListLongPress,\n\t\tthis.handleNoteListTapAfterSelect,\n\t);\n\n\t@override\n\tWidget build(BuildContext context) {\n\t\treturn ListView.builder(\n\t\t\titemCount: data.length,\n\t\t\titemBuilder: (context, index) {\n\t\t\t\tdynamic item = data[index];\n\t\t\t\treturn DisplayNotes(\n\t\t\t\t\titem,\n\t\t\t\t\tselectedNoteIds,\n\t\t\t\t\t(selectedNoteIds.contains(item['id']) == false? false: true),\n\t\t\t\t\tafterNavigatorPop, \n\t\t\t\t\thandleNoteListLongPress,\n\t\t\t\t\thandleNoteListTapAfterSelect,\n\t\t\t\t);\n\t\t\t}\n\t\t);\n\t}\n}\n\n\n// A Note view showing title, first line of note and color\nclass DisplayNotes extends StatelessWidget {\n\tfinal notesData;\n\tfinal selectedNoteIds;\n\tfinal selectedNote;\n\tfinal callAfterNavigatorPop;\n\tfinal handleNoteListLongPress;\n\tfinal handleNoteListTapAfterSelect;\n\n\tDisplayNotes(\n\t\tthis.notesData,\n\t\tthis.selectedNoteIds,\n\t\tthis.selectedNote,\n\t\tthis.callAfterNavigatorPop,\n\t\tthis.handleNoteListLongPress,\n\t\tthis.handleNoteListTapAfterSelect,\n\t);\n\n\t@override\n\tWidget build(BuildContext context) {\n\t\treturn Padding(\n\t\t\tpadding: const EdgeInsets.symmetric(horizontal: 8.0, vertical: 2.0),\n\t\t\tchild: Material(\n\t\t\t\televation: 1,\n\t\t\t\tcolor: (selectedNote == false? Color(c1): Color(c8)),\n\t\t\t\tclipBehavior: Clip.hardEdge,\n\t\t\t\tborderRadius: BorderRadius.circular(5.0),\n\t\t\t\tchild: InkWell(\n\t\t\t\t\tonTap: () {\n\t\t\t\t\t\tif (selectedNote == false) {\n\t\t\t\t\t\t\tif (selectedNoteIds.length == 0) {\n\t\t\t\t\t\t\t\t// Go to edit screen to update notes\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\thandleNoteListLongPress(notesData['id']);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} \n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\thandleNoteListTapAfterSelect(notesData['id']);\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\n\t\t\t\t\tonLongPress: () {\n\t\t\t\t\t\thandleNoteListLongPress(notesData['id']);\n\t\t\t\t\t},\n\t\t\t\t\tchild: Container(\n\t\t\t\t\t\twidth: MediaQuery.of(context).size.width,\n\t\t\t\t\t\tpadding: const EdgeInsets.symmetric(horizontal: 8.0, vertical: 8.0),\n\t\t\t\t\t\tchild: Row(\n\t\t\t\t\t\t\tchildren: \u003cWidget\u003e[\n\t\t\t\t\t\t\t\tExpanded(\n\t\t\t\t\t\t\t\t\tflex: 1,\n\t\t\t\t\t\t\t\t\tchild: Column(\n\t\t\t\t\t\t\t\t\t\tmainAxisAlignment: MainAxisAlignment.center,\n\t\t\t\t\t\t\t\t\t\tcrossAxisAlignment: CrossAxisAlignment.center,\n\t\t\t\t\t\t\t\t\t\tmainAxisSize: MainAxisSize.min,\n\t\t\t\t\t\t\t\t\t\tchildren: \u003cWidget\u003e[\n\t\t\t\t\t\t\t\t\t\t\tContainer(\n\t\t\t\t\t\t\t\t\t\t\t\talignment: Alignment.center,\n\t\t\t\t\t\t\t\t\t\t\t\tdecoration: BoxDecoration(\n\t\t\t\t\t\t\t\t\t\t\t\t\tcolor: (selectedNote == false? \n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColor(NoteColors[notesData['noteColor']]['b']):\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColor(c9)\n\t\t\t\t\t\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\t\t\t\t\t\tshape: BoxShape.circle,\n\t\t\t\t\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\t\t\t\t\tchild: Padding(\n\t\t\t\t\t\t\t\t\t\t\t\t\tpadding: EdgeInsets.all(10),\n\t\t\t\t\t\t\t\t\t\t\t\t\tchild: (\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tselectedNote == false?\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tText(\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnotesData['title'][0],\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tstyle: TextStyle(\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcolor: Color(c1),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfontSize: 21,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t):\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tIcon(\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tIcons.check,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcolor: Color(c1),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsize: 21,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\t),\n\n\t\t\t\t\t\t\t\tExpanded(\n\t\t\t\t\t\t\t\t\tflex: 5,\n\t\t\t\t\t\t\t\t\tchild: Column(\n\t\t\t\t\t\t\t\t\t\tmainAxisAlignment: MainAxisAlignment.spaceAround,\n\t\t\t\t\t\t\t\t\t\tcrossAxisAlignment: CrossAxisAlignment.start,\n\t\t\t\t\t\t\t\t\t\tmainAxisSize: MainAxisSize.min,\n\t\t\t\t\t\t\t\t\t\tchildren:\u003cWidget\u003e[\n\t\t\t\t\t\t\t\t\t\t\tText(\n\t\t\t\t\t\t\t\t\t\t\t\tnotesData['title'] != null? notesData['title']: \"\",\n\t\t\t\t\t\t\t\t\t\t\t\tstyle: TextStyle(\n\t\t\t\t\t\t\t\t\t\t\t\t\tcolor: Color(c3),\n\t\t\t\t\t\t\t\t\t\t\t\t\tfontSize: 18,\n\t\t\t\t\t\t\t\t\t\t\t\t\tfontWeight: FontWeight.bold,\n\t\t\t\t\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\t\t\t\t),\n\n\t\t\t\t\t\t\t\t\t\t\tContainer(\n\t\t\t\t\t\t\t\t\t\t\t\theight: 3,\n\t\t\t\t\t\t\t\t\t\t\t),\n\n\t\t\t\t\t\t\t\t\t\t\tText(\n\t\t\t\t\t\t\t\t\t\t\t\tnotesData['content'] != null? notesData['content'].split('\\n')[0]: \"\",\n\t\t\t\t\t\t\t\t\t\t\t\tstyle: TextStyle(\n\t\t\t\t\t\t\t\t\t\t\t\t\tcolor: Color(c7),\n\t\t\t\t\t\t\t\t\t\t\t\t\tfontSize: 16,\n\t\t\t\t\t\t\t\t\t\t\t\t\tfontWeight: FontWeight.w300,\n\t\t\t\t\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t),\n\t\t\t\t\t),\n\t\t\t\t),\n\t\t\t),\n\t\t);\n\t}\n}\n```\n\n**AllNoteLists** builds a list of notes from the Map of a list of notes. In **ListView** builder it passes each note extracted data to another widget **DisplayNotes** which represents each note. \n\nNow Home screen displays all notes stored as\n\n![Home screen:=:30](note-app-flutter/notes-app-home-notes-list.jpg)\n\nLong press on the note to select the note. And if a note is selected we can add a delete action to delete the selected notes. Add **Delete** button at **appBar** **actions** which shows delete icon only if any note is selected.\n\n```dart\nactions: [\n\t(selectedNoteIds.length \u003e 0?\n\t\tIconButton(\n\t\t\ticon: const Icon(\n\t\t\t\tIcons.delete,\n\t\t\t\tcolor: const Color(c1),\n\t\t\t),\n\t\t\ttooltip: 'Delete',\n\t\t\tonPressed: () =\u003e handleDelete(),\n\t\t):\n\t\tContainer()\n\t),\n],\n```\n\nDefine **hanldeDelete()** which deletes all selected notes from database.\n\n```dart\n// Delete Notes\nvoid handleDelete() async {\n\ttry {\n\t\tNotesDatabase notesDb = NotesDatabase();\n\t\tawait notesDb.initDatabase();\n\t\tfor (int id in selectedNoteIds) {\n\t\t\tint result = await notesDb.deleteNote(id);\n\t\t}\n\t\tawait notesDb.closeDatabase();\n\t} catch (e) {\n\t\tprint('Cannot delete notes');\n\t} finally {\n\t\tsetState(() {\n\t\t\tselectedNoteIds = [];\n\t\t});\n\t}\n}\n```\n\nFor notes, we have added create, read and delete functions. Now we will add an update function to edit already stored notes.\n\n### Update notes\n\nFor this, we can use the Edit screen to update the notes as it has all features to create notes which are similar for update notes also. We have to tell the Edit screen which type of notes operations we doing either create or update notes. To inform the Edit screen we can pass arguments to **NotesEdit** widget while routing about the type of action and notes data if the action is to update. Change **NotesEdit** widget to accept arguments telling the type of action and necessary data.\n\n```dart\nclass NotesEdit extends StatefulWidget {\n\tfinal args;\n\n\tconst NotesEdit(this.args);\n\t_NotesEdit createState() =\u003e _NotesEdit();\n}\n```\n\n**args** stores parameters passed from parent widget.\n\nChange navigation arguments for **NotesEdit** in the floating-action-button in **_Home**.\n\n```dart\n//Floating Button\nfloatingActionButton: FloatingActionButton(\n\tchild: const Icon(\n\t\tIcons.add,\n\t\tcolor: const Color(c5),\n\t),\n\ttooltip: 'New Notes',\n\tbackgroundColor: const Color(c4),\n\tonPressed: () {\n\t  Navigator.push(\n\t  \tcontext,     \n\t    MaterialPageRoute(builder: (context) =\u003e NotesEdit(['new', {}])),\n\t  );\n\t}\n),\n```\n\nAs floating-button triggers the creation of a new note, we pass argument **new** to inform **NotesEdit** that operation in creation of note.\n\nWhen tapped on a note on the Home screen we navigate to the Edit screen to update the note. For this add navigation from Home to Edit when tapped on the note in **DisplayNotes**.\n\n```dart\nchild: InkWell(\nonTap: () {\n\tif (selectedNote == false) {\n\t\tif (selectedNoteIds.length == 0) {\n\t\t\tNavigator.push(\n\t\t\t\tcontext, \n        MaterialPageRoute(\n          builder: (context) =\u003e NotesEdit(['update', notesData]),\n        ),\n\t\t\t).then((dynamic value) {\n\t\t\t\t\tcallAfterNavigatorPop();\n\t\t\t\t}\n\t\t\t);\n\t\t\treturn;\t\t\n\t\t}\n\t\telse {\n\t\t\thandleNoteListLongPress(notesData['id']);\n\t\t}\n\t} \n\telse {\n\t\thandleNoteListTapAfterSelect(notesData['id']);\n\t}\n},\n```\n\nWe pass **update** and **notesData** to the Edit screen stating the operation is updating notes and note data to fill in the Edit screen.\n\nChange **NotesEdit** widget in **notes_edit.dart** for handling update note operation.\n\n```dart\n@override\nvoid initState() {\n\tsuper.initState();\n\tnoteTitle = (widget.args[0] == 'new'? '': widget.args[1]['title']);\n\tnoteContent = (widget.args[0] == 'new'? '': widget.args[1]['content']);\n\tnoteColor = (widget.args[0] == 'new'? 'red': widget.args[1]['noteColor']);\n\n\t_titleTextController.text = (widget.args[0] == 'new'? '': widget.args[1]['title']);\n\t_contentTextController.text = (widget.args[0] == 'new'? '': widget.args[1]['content']);\n\t_titleTextController.addListener(handleTitleTextChange);\n\t_contentTextController.addListener(handleNoteTextChange);\n}\n\nvoid handleBackButton() async {\n\tif (noteTitle.length == 0) {\n\t\t// Go Back without saving\n\t\tif (noteContent.length == 0) {\n\t\t\tNavigator.pop(context);\n\t\t\treturn;\n\t\t}\n\t\telse {\n\t\t\tString title = noteContent.split('\\n')[0];\n\t\t\tif (title.length \u003e 31) {\n\t\t\t\ttitle = title.substring(0, 31);\n\t\t\t}\n\t\t\tsetState(() {\n\t\t\t\tnoteTitle = title;\n\t\t\t});\n\t\t}\n\t}\n\n\t// Save New note\n\tif (widget.args[0] == 'new') {\n\t\tNote noteObj = Note(\n\t\t\ttitle: noteTitle, \n\t\t\tcontent: noteContent, \n\t\t\tnoteColor: noteColor\n\t\t);\n\t\ttry {\n\t\t\tawait _insertNote(noteObj);\n\t\t} catch (e) {\n\n\t\t} finally {\n\t\t\tNavigator.pop(context);\n\t\t\treturn;\n\t\t}\n\t}\n\t\n\t// Update Note\n\telse if (widget.args[0] == 'update') {\n\t\tNote noteObj = Note(\n\t\t\tid: widget.args[1]['id'],\n\t\t\ttitle: noteTitle, \n\t\t\tcontent: noteContent, \n\t\t\tnoteColor: noteColor\n\t\t);\n\t\ttry {\n\t\t\tawait _updateNote(noteObj);\n\t\t} catch (e) {\n\n\t\t} finally {\n\t\t\tNavigator.pop(context);\n\t\t\treturn;\n\t\t}\n\t}\n}\n```\n\nTapping on the note in the Home screen will take us to the Edit screen to update notes.\n\n---\n\nThis tutorial addressed how to create a simple note-taking app in Flutter with common operations like create, read, update and delete. We can extend the app to have multiple day-to-day useful features. I hope you will do that to create your own notes app according to your interests and needs.\n\nI have created a full Android working application with additional features like Notes sharing, multi-select notes, deleting notes in the edit screen, sort text in notes, etc. Check out the full code at [github.com/santhalakshminarayana/zehero-note](https://github.com/santhalakshminarayana/zehero-note)."},{"metadata":{"title":"Build Blog with Next.js and MDX \u0026 Deploy to Github Pages","description":"Create a blog with Next.js as Static Site Generator, MDX for writing content, Github Pages for deploying the static website. Also add SEO and Image optimization.","imgName":"blog-nextjs-mdx/nextjs.jpeg","date":"Dec 31, 2020","tags":["react","next-js"],"keywords":["react'","next.js","blog","mdx","markdown","gh-pages","github-pages"],"id":"build-blog-with-nextjs-mdx-and-deploy-to-github-pages"},"content":"\n![Build Blog with Next.js \u0026 MDX and Deploy to Github Pages](blog-nextjs-mdx/nextjs.jpeg)\n\n# Build Blog with Next.js \u0026 MDX and Deploy to Github Pages\n\nIn this post, we will discuss how to create and publish a blog with [Next.js](https://nextjs.org/), write content with [MDX](https://mdxjs.com/), deploy static site to Github Pages, Image optimization to reduce the page load time and SEO for better page ranking.\n\n\u003e Pre-requisites: Basic understanding of React and Markdown. \n\nBuilding a blog with Next.js is very easy and it is simple to understand, develop, and maintain the dynamic websites and credit goes to Next.js dynamic paging which lets the creation of dynamic URLs and routing. When I decided to start my blog then I searched and read about many frameworks like Vanilla React, Gatsby, Hugo, etc., After reading many blogs, comments, and reviews I felt Next.js would be the option I was looking for. \n\nNext.js offers everything need to create a blog:\n- Static site export support\n- Dynamic routing\n- MDX (markdown with JSX) support\n- Image optimization\n- SEO\n\nNow dive in to create a simple blog\n\n## Setup Next.js and MDX\nNext.js is a React framework to create SPA (single page applications) and enables both static websites and server-side rendering. Here we'll focus only on static website generation.\n\n### Install Next.js\n\n[Install Next.js](https://nextjs.org/docs/getting-started#setup) by typing any of the following commands\n\n```bash\nnpx create-next-app\n# or\nyarn create next-app\n```\n\n_create-next-app_ installs everything needed to start with. \n\nThe most important thing in Next.js is the **pages** directory. Every component exported from **.js**, **.jsx**, **.ts**, or **.tsx** in the pages folder is treated as a page and each page associates with a route based on its file name. In the pages folder, the **App** component from **\\_app.js** serves as the initialization of pages that can be edited for custom use like global style declaration, CDN's, etc., **index.js** is the starting point for adding content.\n\nTo write content in articles we use MDX, which lets us write JSX in Markdown (**.mdx** file). Writing in markdown is as beautiful as it is like writing in a text file and can render as HTML tags. Besides easy export and maintenance of articles, we can also reuse these files in another framework/platform which supports MDX without rewriting.\n\n### Install MDX\n\nInstall necessary plugins for MDX\n\n```bash\nyarn add @next/mdx gray-matter next-mdx-remote\n```\n\nWe installed _@next/mdx_ to handle **.mdx** files in pages directory, _gray-matter_ is to parse content from markdown and _next-mdx-remote_ for rendering markdown as HTML.\n\nNow create / open **next.config.js** (configuration file for Next.js) at the project root level and add the following to configure MDX and handle **.mdx** page extensions in the pages folder.\n\n```js\nconst withMDX = require('@next/mdx')({\n  extension: /\\.mdx?$/,\n})\nmodule.exports = withMDX({\n  pageExtensions: ['js', 'jsx', 'mdx'],\n  target: 'serverless',\n})\n``` \nAs Next.js only looks for **.js** or **.jsx** files and gives routing to these pages, the above configuration tells Next.js to treat **.md** or **.mdx** files as pages and provide routing.\n\nAs we are creating a static site, **target: 'serverless'** notifies Next.js to generate static files for us.\n\nOpen **package.json** file in the root directory and add **deploy** command to export all static files as a folder as **out** (can have a different name) at the root level. After installing plugins and adding values **package.json** might look like this\n\n```json\n{\n  \"name\": \"blog\",\n  \"version\": \"0.1.0\",\n  \"private\": true,\n  \"scripts\": {\n    \"dev\": \"next dev\",\n    \"build\": \"next build\",\n    \"start\": \"next start\",\n    \"export\": \"next export\",\n    \"deploy\": \"npm run build \u0026\u0026 npm run export\"\n  },\n  \"dependencies\": {\n    ---\n  }\n}\n\n```\n\nLet's give some break to configuration and take a turn to add some content.\n\n## Home Page\n\nAs said earlier **index.js** is the pivot file and also the Home page for our website. So let's edit our Home page and customize it like below.\n\n```js:pages/index.js\nexport default function Home() {\n  return (\n    \u003cdiv className = 'info-container'\u003e\n      \u003cimg src = 'batman.png' alt = 'Batman Logo'/\u003e\n      \u003cp className = 'info-description'\u003eHi I'm Batman, the saviour of Gotham City and I like to roam in nights to bash the bad guys.\u003c/p\u003e\n      \u003cp className = 'info-description'\u003eBut please don't call me as a source for \u003cb\u003eCorona Virus\u003c/b\u003e and it could be the \u003cb\u003eJoker\u003c/b\u003e who \n      might have started this mess.\u003c/p\u003e\n\n      \u003cstyle jsx\u003e{`\n        .info-container {\n          margin: 0 5% 0 5%;\n        }\n\n        img {\n          width: 20%;\n          max-width: 20%;\n          height: auto;\n          margin-left: 40%;\n        }\n\n        .info-description {\n          font-size: 20px;\n        }\n      `}\u003c/style\u003e\n    \u003c/div\u003e\n  )\n}\n```\n\nIn the above snippet, **CSS** styles are provided inside the component. This is called **CSS-In-JS**, which is possible as Next.js bundles **styled-jsx**. There are many ways to add [CSS in Next.js](https://nextjs.org/docs/basic-features/built-in-css-support).\n\nIn the **img** tag above, **src** is provided with the name of the image only but not relative/absolute path. In Next.js we don't need to provide complete paths if we place any assets (like images, videos) in the **public** folder. Next.js automatically prepends the path at build time for assets in the public folder.\n\nNow to see changes, start localhost (default port is 3000) as a dev server\n```bash\n# starts localhost at port 8000\nyarn dev -p 8000\n```\n\nOpen any desktop browser and type URL http://localhost:port/ to see changes.\nFor the above code, the display is like below\n\n![First preview](blog-nextjs-mdx/nextjs-blog-display.jpg)\n\nWe have a home page with a welcome message. Now some create blog posts with MDX.\n\n## Write Blog Content with MDX\n\nCreate a directory to store our markdown posts at the root level or any accessible place. \n\n```shell\nmkdir posts\n```\n\nWrite some content in a markdown file and save it as '.mdx' inside the **posts** directory. I have created two posts and saved them as **batman-vs-superman.mdx** and **justice-league.mdx**.\n\n```markdown:posts/batman-vs-superman.mdx\n---\ntitle: \"Batman VS Superman\"\ndescription: \"An intense fight between two superheroes, me and Superman.\"\ndate: \"Mar 25, 2016\"\n---\n\n# Batman VS Superman\n\nI and Superman accidentally met (fight) and later realized there was a culprit (Lex Luthor) who we should fight.\n\nAs usual, it cost a whopping $250 million for this high-action story.\n```\n\n```markdown:posts/justice-league.mdx\n---\ntitle: \"Justice League\"\ndescription: \"Grand union with fellow superheroes which costs $300 million but received face slap from the audience.\"\ndate: \"Nov 17, 2017\"\n---\n\n# Justice League\n\nSuperheroes from the DC universe consisting of Superman, Wonder Woman, The Flash, Aquaman, and Cyborg and I met in 2017 to spoil the party plans of Steppenwolf who tried to steal Mother Boxes on Earth.\n\nIt's a very long story of how we met each other and all thanks to Avengers who had inspired me to search for other superheroes.\n```\n\nIn the above snippet content inside **---** is used as metadata to make routing for this **.mdx** file. We'll discuss this later.\n\n## Show blog posts on the Home page\n\n### Fetch posts data\n\nTo show our blog posts on the Home page, we have to fetch the **.mdx** files and parse content. We can also provide routing from the home page to any blog post. We write the logic to fetch the **.mdx** files to read the content inside and extract metadata useful to display posts on the Home page. These files should be separated from routing, so at the root level create a folder called **lib** where we store all program files to extract **.mdx** content. Inside **lib** create a file with name **getPostsData.js** which returns posts data like markdown content, title, path, etc.,\n\n```js:lib/getPostsData.js\nconst fs = require('fs');\nconst path = require('path');\nconst matter = require(\"gray-matter\");\n\n// current 'posts' directory\nconst postsDirectory = path.join(process.cwd(), 'posts');\nconst mdx_file_extention = '.mdx';\n\nfunction getAllFilesInDirectory() {\n  const fileNames = fs.readdirSync(postsDirectory);\n  return fileNames.map((fileName) =\u003e {\n    return path.parse(fileName)\n  })\n}\n\nfunction getMdxFiles() {\n  const allFiles = getAllFilesInDirectory();\n  return allFiles.filter(parsedFile =\u003e parsedFile.ext == mdx_file_extention);\n}\n\nexport function getAllPostsPath() {\n  const allMdxFiles = getMdxFiles();\n  return allMdxFiles.map((parsedFile) =\u003e {\n    return {\n      params: {\n        id: parsedFile.name\n      }\n    }\n  })\n}\n\nexport function getPostsMetaData() {\n  const allMdxFiles = getMdxFiles();\n\n  const postsMetaData = allMdxFiles.map((parsedFile) =\u003e {\n    const fullPath = path.join(postsDirectory, parsedFile.base);\n\n    // get MDX metadata and content\n    const fileContents = fs.readFileSync(fullPath, 'utf8');\n    // get metadata, content\n    const { data, content } = matter(fileContents);\n    let metadata = data;\n    metadata['id'] = parsedFile.name;\n    return metadata;\n  });\n  return postsMetaData;\n}\n\nexport function getPostData(id) {\n  const fullPath = path.join(postsDirectory, id + mdx_file_extention);\n\n  // get MDX metadata and content\n  const fileContents = fs.readFileSync(fullPath, 'utf8');\n  // get metadata, content\n  const { data, content } = matter(fileContents);\n\n  let metadata = data;\n  metadata['id'] = id;\n\n  return {'metadata': metadata, 'content': content};\n}\n```\n\n**getAllPostsPath** function returns all **.mdx** files path names to serve as URLs for dynamic routing of a page.\n\n**getPostsMetaData** function returns all **.mdx** files metadata (data inside **---**) which we use to gather information like title, description, etc., and function **getPostsData** returns both metadata and markdown content to render for a particular file we request through argument **id**. **gray-matter** parses the markdown file into metadata (data inside **---**) and markdown content to render.\n\nIf encountered error while accessing **fs** add the following to _next.config.js_\n\n```js:next.config.js\nconst withMDX = require('@next/mdx')({\n  extension: /\\.mdx?$/,\n})\n\nmodule.exports = withMDX({\n\twebpack: (config, { isServer }) =\u003e {\n\t\tif (!isServer) {\n\t  \tconfig.node = {\n\t    fs: 'empty'\n\t \t\t}\n\t\t}\n\treturn config\n\t},\n  pageExtensions: ['js', 'jsx', 'mdx'],\n  target: 'serverless',\n})\n```\n### Provide posts data to Home page\n\nWe have to call the **getallPostsData** function to get data. But how can we pass this data to the component in **pages/index.js**? Don't worry we can pass data as **props** to the component before rendering using the [getStaticProps](https://nextjs.org/docs/basic-features/data-fetching#getstaticprops-static-generation) function. **getStaticProps** allows us to fetch any dynamic data to provide before rendering the component. Change **pages/index.js** as \n\n```js:pages/index.js\nimport { getPostsMetaData } from '../lib/getPostsData.js';\n\nexport default function Home({ postsData }) {\n  return (\n    \u003cdiv className = 'info-container'\u003e\n      \u003cimg src = 'batman.png' alt = 'Batman Logo'/\u003e\n      \u003cp className = 'info-description'\u003eHi I'm Batman, the saviour of Gotham City and I like to roam in nights to bash the bad guys.\u003c/p\u003e\n      \u003cp className = 'info-description'\u003eBut please don't call me as a source for \u003cb\u003eCorona Virus\u003c/b\u003e and it could be the \u003cb\u003eJoker\u003c/b\u003e who \n      might have started this mess.\u003c/p\u003e\n      \u003chr/\u003e\n      {postsData.map((metadata) =\u003e {\n        return (\n          \u003cdiv key = {metadata.id}\u003e\n            \u003ch2 className = 'post-title'\u003e{metadata.title}\u003c/h2\u003e\n            \u003cp className = 'post-description'\u003e{metadata.description}\u003c/p\u003e\n          \u003c/div\u003e\n          )\n        })}\n\n      \u003cstyle jsx\u003e{`\n        .info-container {\n          margin: 0 5% 0 5%;\n        }\n\n        img {\n          width: 20%;\n          max-width: 20%;\n          height: auto;\n          margin-left: 40%;\n        }\n\n        .info-description {\n          font-size: 20px;\n        }\n\n        .post-title {\n          font-size: 24px;\n          color: black;\n        }\n\n        .post-description {\n          font-size: 16px;\n          color: #000000e6;\n        }\n      `}\u003c/style\u003e\n    \u003c/div\u003e\n  )\n}\n\nexport async function getStaticProps() {\n  const postsData = getPostsMetaData();\n  return {\n    props: {\n      postsData: postsData,\n    }\n  }\n}\n```\n\nWhich displays as \n\n![MDX blog posts display on Home page](blog-nextjs-mdx/blog-posts-display-on-home-page.jpg)\n\n## Rendering MDX and providing dynamic routing\n\nSo far so good until we want to display **.mdx** files as individual webpages. Right now it is not possible because Next.js only treats components exported inside the **pages** folder as webpages and provides routing, to provide routing for our posts we must export content from the **posts** directory to the **pages** folder. This is where we should spend some time to serve markdown files as webpages. \n\nThe beauty of Next.js is that we can dynamically serve pages by fetching these **.mdx** files and provide routing inside the **pages** directory with having dynamic pages.\n\nCreate **blog** folder inside the **pages** folder and inside this **blog** folder create a file with name **[id].js**. Dynamic routes in Next.js are identified by **[]** (square brackets) in the filename. We can provide any query parameter to this **[]** page component which will end up as *http://localhost:8000/blog/post-name* for **post-name.js**. Now add following code to *pages/blog/**[id]**.js*\n\n```js:pages/blog/[id].js\nimport { serialize } from 'next-mdx-remote/serialize';\nimport { MDXRemote } from 'next-mdx-remote';\nimport { getAllPostsPath, getPostData } from '../../lib/getPostsData.js';\n\nconst components = {\n\th1: props =\u003e \u003ch1 style = {{ \n\t\tfontSize: 'calc(1rem + 1.5vw)', \n\t\tcolor: 'black',\n\t\tmargin: '1vh 0 1vh 0', }} \n\t\t{...props} /\u003e,\n\n\tp: props =\u003e \u003cp style = {{ \n\t\tfontSize: 'calc(1rem + 0.1vw)', \n\t\tcolor: '#000000e6',\n\t\tmargin: '0vh 0 1vh 0' }} \n\t\t{...props} /\u003e,\n}\n\nexport default function Blog({ postMetadata, postContent }) {\n\n\treturn (\n\t\t\u003cdiv\u003e\n\t\t\t\u003cdiv className = 'blog-content'\u003e\n\t\t\t\t\u003cMDXRemote {...postContent} components = {components} /\u003e \n\t\t\t\u003c/div\u003e\n\n\t\t\t\u003cstyle jsx\u003e{`\n\t\t\t\t.blog-content {\n\t\t\t\t\tdisplay: flex;\n\t\t\t\t\tflex: 100%;\n\t\t\t\t\tflex-direction: column;\n\t\t\t\t\tmargin: 1vw 25vw 1vw 25vw;\n\t\t\t\t\twidth: 50vw;\n\t\t\t\t\tmax-width: 50vw;\n\t\t\t\t}\n\t\t  `}\u003c/style\u003e\n\t\t\t\n\t\t\u003c/div\u003e\n\t)\n}\n\nexport async function getStaticPaths() {\n\tconst paths = getAllPostsPath();\n\treturn {\n\t\tpaths,\n\t\tfallback: false,\n\t}\n}\n\nexport async function getStaticProps({ params }) {\n\tconst postData = await getPostData(params.id);\n\tconst mdxSource = await serialize(postData.content);\n\treturn {\n\t\tprops: {\n\t\t\tpostMetadata: postData.metadata,\n\t\t\tpostContent: mdxSource,\n\t\t\tid: params.id,\n\t\t}\n\t}\n}\n```\n\nIf any page provides dynamic routing we must provide all dynamic paths we want to serve to this page through the [getStaticPaths](https://nextjs.org/docs/basic-features/data-fetching#getstaticpaths-static-generation) function.\n\nWith **serialize** and **MDXRemote**, we parse markdown content to HTML string and render it as plain HTML. To style the HTML tags in markdown, we pass custom tags as components to the MDX loader which maps tags automatically. In the above file two tags, **h1** and **p** are customized and combined as components.\n\nNow, in the browser, hit URL *http://localhost:3000/blog/batman-vs-superman* or *http://localhost:3000/blog/justice-league* to see the post. You might see output similar to below\n\n![MDX Post Display](blog-nextjs-mdx/mdx-post-display.jpg)\n\n## Navigation from the Home page\n\nWhat if we want to navigate from the Home page to blog posts by clicking on the title of the post? For this Next.js provides a [next/link](https://nextjs.org/docs/api-reference/next/link) component that takes care of dynamic routing from any page to another by pre-pending the necessary path before the page to navigate like navigation to **batman-vs-superman** results as *http://localhost:3000/blog/batman-vs-superman*. We must navigate like this only if we are not pre-pending the base URL manually inside the website. Now change **pages/index.js** to get dynamic navigation\n\n```js\nimport Link from 'next/link';\n{ ... }\n\n{postsData.map((metadata) =\u003e {\n  return (\n    \u003cdiv key = {metadata.id}\u003e\n      \u003cLink href={`/blog/${metadata.id}`} key = {metadata.title} \u003e\n        \u003ca className = 'post-title'\u003e{metadata.title}\u003c/a\u003e\n      \u003c/Link\u003e\n      \u003cp className = 'post-description'\u003e{metadata.description}\u003c/p\u003e\n    \u003c/div\u003e\n    )\n  })}\n\n { ... }\n```\n\n## Image Optimization\n\nImages take a lot of space in a webpage which reduces page loading time results in poor performance if the user has a poor internet connection. Images can be optimized many ways like converting all PNG/JPEG files to Webp/JPEG2000 format, [responsive images](https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images) for different screen dimensions by rescaling images, lazy loading, etc.,\n\nNext.js provides [next/image](https://nextjs.org/docs/api-reference/next/image) API for image optimization. But it needs the **next start** that runs on the node server which is not possible for static site generation. So we will use another plugin [next-optimized-images](https://github.com/cyrilwanner/next-optimized-images) which provides many options to optimize images.\n\nHere we will optimize images to serve in Webp format, to do so install **next-optimized-images**\n\n```shell\nnpm install next-optimized-images\n```\n\nBesides this install some additional plugins to convert PNG/JPEG to Webp format and loading Webp images.\n\n```shell\nnpm install imagemin-mozjpeg imagemin-optipng webp-loader\n```\n\nand change _next.config.js_ as\n\n```js:next.config.js\nconst withNextOptimizedImages = require('next-optimized-images');\n\nconst withMDX = require('@next/mdx')({\n  extension: /\\.mdx?$/,\n})\n\nmodule.exports = withNextOptimizedImages(\n\twithMDX({\n\t\twebpack: (config, { isServer }) =\u003e {\n\t\t\t\tif (!isServer) {\n\t\t  \t\tconfig.node = {\n\t\t    \tfs: 'empty'\n\t\t \t\t}\n\t\t\t}\n\t\t\treturn config\n\t\t},\n\t  pageExtensions: ['js', 'jsx', 'mdx'],\n\t  target: 'serverless',\n\t})\n)\n```\n\nIn build time **next-optimized-images** exports optimized images to **images** (custom name) folder inside _out/_next/static_. So create **images** directory at the root level and move images to this folder which needs optimization and provide relative paths now which were previously not required because of the **public** folder.\n\nChange the **img** tag in **pages/index.js** to\n\n```jsx\n\u003cpicture\u003e\n  \u003csource srcSet={require('../images/batman.png?webp')} type=\"image/webp\" /\u003e\n  \u003csource srcSet={require('../images/batman.png')} type=\"image/png\" /\u003e\n  \u003cimg src={require('../images/batman.png')} alt = 'Batman Logo' /\u003e\n\u003c/picture\u003e\n```\n\nThis will convert a PNG image to Webp format and loads Webp images. If the browser doesn't support Webp images **\u003cpicture\\\u003e** will automatically load the normal PNG image.\n\nYou can more than this by exploring more about this plugin.\n\n## SEO in Next.js\n\nFor Single Application Websites (SPA) SEO is a major problem which Next.js takes care of this by providing API [next/head](https://nextjs.org/docs/api-reference/next/head) which behaves exactly like **\u003chead\\\u003e** in HTML. We can wrap meta properties, title, description, Open Graph (OG) properties, Twitter cards, etc., inside the **Head** component. For our Home page we can set title and description as \n\n![Seo in Next.js:=:80](blog-nextjs-mdx/seo-in-nextjs.jpg)\n\nIf you don't want to set meta properties, title, description, and others there are so many plugins like [next-seo](https://www.npmjs.com/package/next-seo) available which handle all of these manual adding for you.\n\n---\n\n## Deploy to Github pages\n\n### Export static files to deploy\n\nNow our website is ready to move from development to production. To host our site we can use the static-site-generator of Next.js to generate all pre-render pages bundled inside the **out** directory. Build and generate **out** directory by typing the below command in the terminal\n\n```shell\nyarn deploy\n```\n\nYou can find a new directory **out** at the root level which contains all dynamic pages pre-rendered and ready to serve as HTML pages on the client-side. We will use this folder to host our website on Github pages.\n\n### Set up Github Pages\n\nGithub Pages is a very great place to host static sites. But we need to push and configure deployment changes every time we add content to the website. This is where we utilize Github Actions which automates deployment actions according to the configuration file we provide. But first, create a repository in Github to store our code files and push source code to this repository on the **main** branch. We use the **gh-pages** branch to which Github Actions deploy static files for hosting. \n\nTo do this we must provide access for Github Actions to this repository to access source files. To provide access, go to [Github Settings -\u003e tokens](https://github.com/settings/tokens) and create a new **personal access token** by checking **repo** scopes and others if you need and save as **GITHUB_TOKEN** (or any other name). Copy this **access code** and in the repository, move to the **secretes** tab in the **Settings** section and create a new secrete and copy this code. Remember the name of the secrete token you created in this repo for future purposes. \n\n![Github Repository Secretes Token:=:80](blog-nextjs-mdx/github-repo-secretes-token.jpg)\n\nIt's time to configure GitHub Actions. Create a directory called _.github/workflows_ at the root level locally. Create a file **integrate.yml** inside _.github/workflows_ and add the following configuration\n\n```yaml:.github/workflows/integrate.yml\nname: Build and Deploy\non: \n  push:\n    branches:\n      - master\njobs:\n  build-and-deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2.3.1\n        with:\n          persist-credentials: false\n\n      - name: Cache\n        uses: actions/cache@v2\n        with:\n          path: ${{ github.workspace }}/.next/cache\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}\n\n      - name: Install and Build\n        uses: actions/setup-node@v1\n      - run: npm install\n      - run: npm run build\n      - run: npm run export\n        env:\n            CI: true\n      - run: touch out/.nojekyll\n\n      - name: Deploy\n        uses: JamesIves/github-pages-deploy-action@3.7.1\n        with:\n          ACCESS_TOKEN: ${{ secrets.ACCESS_TOKEN }}\n          BRANCH: gh-pages \n          FOLDER: out\n          CLEAN: true\n```\nYou may have to replace **ACCESS_TOKEN** with your custom name. This is what we configured\n\n1. Execute workflow action on every push to the **master** branch.\n2. Run commands *npm install \u0026\u0026 npm run build \u0026\u0026 npm run export* to build and export static version of our website.\n3. Deploy contents inside **out** folder to the **gh-pages** branch.\n4. Added *touch out/.nojekyll* to **gh-pages** because Github pages **Jekyll** to render static sites. **Jekyll** ignores files in the directory starting with **_** and it is an issue for us because all our static assets are created in **\\_next** folder. **.nojekyll** tells Github Pages not to run published files through **Jekyll**.\n\nPush all changes to Github repo\n\n```shell\ngit add .\ngit commit -m \"initial deployment of the blog\"\ngit push -u origin master\n```\n\nThis will push all your working source files to the Github repo and Github Actions starts a workflow to deploy static files in the **out** folder to **gh-pages**.\n\nYou can monitor the status of the Github Actions workflow after every push to the **master** branch in the **Actions** tab.\n\nEnable Github Pages in the **Settings** section of the repo and for source select the **gh-pages** branch.\n\nIf everything worked properly you can have your website hosted at *https://\u003cusername\\\u003e.github.io/\u003crepo\\\u003e*. Here **\u003crepo\\\u003e** name is **blog**. \n\n---\n\n## Manage CSS, assets, and page links to work properly\n\nIf you host the website at *https://\u003cusername\\\u003e.github.io/\u003crepo\\\u003e* you can observe CSS or other static assets and routing not working properly. This is because Next.js assumes **out** directory hosted at root level as *https://\u003cusername\\\u003e.github.io/* and directs all routing, replaces assets and everything to this basepath. But we have hosted the **out** folder in **blog/out**, so we must add **subpath** **blog** to the **basepath** to manage assets linking and routing. We can do this by changing the configuration in **next.config.js**\n\n```js:next.config.js\nconst ghPages = process.env.DEPLOY_TARGET === 'gh-pages';\n\nconst withNextOptimizedImages = require('next-optimized-images');\n\nconst withMDX = require('@next/mdx')({\n  extension: /\\.mdx?$/,\n})\n\nmodule.exports = withNextOptimizedImages(\n\twithMDX({\n\t\twebpack: (config, { isServer }) =\u003e {\n\t\t\tif (!isServer) {\n\t\t  \tconfig.node = {\n\t\t    fs: 'empty'\n\t\t \t\t}\n\t\t\t}\n\t\t\treturn config\n\t\t},\n\t  pageExtensions: ['js', 'jsx', 'mdx'],\n\t  target: 'serverless',\n\t\tbasePath: ghPages? '/blog/' : '',\n\t\tassetPrefix: ghPages ? '/blog/' : '',\n\t})\n)\n```\n\nWhile developing it works fine everything, so we check the environment phase we are processing with **process.env** and **process.env.DEPLOY_TARGET** tells the current hosted environment. In local development, we run on the **node** server hosted on our machine so we don't need to manage any **basepath** or **subpath**. \n\n**basePath** specifies the base path of the application to manage linking pages. If we are on the **gh-pages**, the base path **/blog/** resolves to **username.github.io/blog/** where **/** is the home path.\n\n**assetPrefix** specifies where to look for assets (CSS, Images, etc.,).\n\n---\n\nAnd here we are with our personal blog on the internet and we can take our blog to next level by adding fancy CSS, custom components, and other pages like **about**, **contact**... I hope you find this articl useful to build your own blog. To check the source code of this website, you can find it at [github.com/santhalakshminarayana/santhalakshminarayana.github.io](https://github.com/santhalakshminarayana/santhalakshminarayana.github.io)."}]},"__N_SSG":true},"page":"/","query":{},"buildId":"pvv6ydTaNkcDcbA_18mts","runtimeConfig":{},"isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>