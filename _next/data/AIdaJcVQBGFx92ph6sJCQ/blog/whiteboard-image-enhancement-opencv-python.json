{"pageProps":{"postMetadata":{"title":"Whiteboard Image Enhancement using OpenCV","description":"Enhance whiteboard images taken from mobile using OpenCV.","imgName":"whiteboard-enhance/whiteboard-image-enhancement.jpg","date":"Oct 19, 2021","tags":["image-processing","opencv"],"keywords":["whiteboard","whiteboard-enhance","image-enhance","image-processing","opencv","python","difference-of-guassian","dog","contrast-stretch","color-balance"],"id":"whiteboard-image-enhancement-opencv-python"},"postContent":{"compiledSource":"var c=Object.defineProperty,g=Object.defineProperties;var h=Object.getOwnPropertyDescriptors;var i=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,m=Object.prototype.propertyIsEnumerable;var p=(e,n,t)=>n in e?c(e,n,{enumerable:!0,configurable:!0,writable:!0,value:t}):e[n]=t,a=(e,n)=>{for(var t in n||(n={}))r.call(n,t)&&p(e,t,n[t]);if(i)for(var t of i(n))m.call(n,t)&&p(e,t,n[t]);return e},o=(e,n)=>g(e,h(n));var l=(e,n)=>{var t={};for(var s in e)r.call(e,s)&&n.indexOf(s)<0&&(t[s]=e[s]);if(e!=null&&i)for(var s of i(e))n.indexOf(s)<0&&m.call(e,s)&&(t[s]=e[s]);return t};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(t){var s=t,{components:e}=s,n=l(s,[\"components\"]);return mdx(MDXLayout,o(a(a({},layoutProps),n),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,mdx(\"img\",a({parentName:\"p\"},{src:\"whiteboard-enhance/whiteboard-image-enhancement.jpg\",alt:\"Whiteboard image enhancement in Python\"}))),mdx(\"h1\",null,\"Whiteboard image enhancement using OpenCV\"),mdx(\"p\",null,\"Whiteboard images generally contain less contrast and low brightness as they would be captured in mobile under normal room light conditions. Enhancing whiteboard images makes text readable and gives an image with high contrast and brightness. \"),mdx(\"p\",null,\"We will apply different image-processing techniques to enhance whiteboard images using OpenCV in Python. From this \",mdx(\"a\",a({parentName:\"p\"},{href:\"https://gist.github.com/lelandbatey/8677901\"}),\"whiteboard-cleaner\"),\" gist that enhances whiteboard images using \",mdx(\"a\",a({parentName:\"p\"},{href:\"https://imagemagick.org/\"}),\"ImageMagick\"),\", we will implement those ImageMagick methods in Python.\"),mdx(\"p\",null,\"In that script, the following ImageMagick functions were used to enhance whiteboard images\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-shell\"}),`-morphology Convolve DoG:15,100,0 -negate -normalize -blur 0x1 -channel RBG -level 60%,91%,0.1\n`)),mdx(\"p\",null,\"Above command applies image enhancing functions in order \"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"-morphology Convolve DoG:15, 100, 0\"),\": Difference of Gaussian (DoG) with kernel_radius=15, sigma1=100, and sigma2=0\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"-negate\"),\": Negative of image\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"-normalize\"),\": Contrast stretch image with black=0.15% and white=0.05%\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"strong\",{parentName:\"li\"},\"-blur 0x1\"),\": Gaussian blur with sigma=1\"),mdx(\"li\",{parentName:\"ul\"},\"**-level 60%,91%,0.1: Stretch image with black=60% and white=91%, and Gamma correction by gamma=0.1\")),mdx(\"p\",null,\"As I found some difficulty for exactly converting the ImageMagick C code to Python, I have changed the order and parameters that would give close results.\"),mdx(\"hr\",null),mdx(\"p\",null,\"We will apply series of image-processing methods and effects to enhance whiteboard images in the following order\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Difference of Gaussian (DoG)\"),mdx(\"li\",{parentName:\"ul\"},\"Negative effect\"),mdx(\"li\",{parentName:\"ul\"},\"Contrast Stretching\"),mdx(\"li\",{parentName:\"ul\"},\"Gaussian blur\"),mdx(\"li\",{parentName:\"ul\"},\"Gamma correction\"),mdx(\"li\",{parentName:\"ul\"},\"Color balance\")),mdx(\"p\",null,\"You can find the full code in my Github repository \",mdx(\"a\",a({parentName:\"p\"},{href:\"https://github.com/santhalakshminarayana/whiteboard-image-enhance\"}),\"whiteboard-image-enhance\")),mdx(\"h3\",null,\"Import packages and read image\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-python\"}),`import cv2\nimport numpy as np\n\nimg = cv2.imread('input.jpg')\n`)),mdx(\"p\",null,mdx(\"img\",a({parentName:\"p\"},{src:\"whiteboard-enhance/whiteboard-image.jpg\",alt:\"Whiteboard image input:=:70:=:Input Whiteboard image\"}))),mdx(\"h3\",null,\"Difference of Gaussian (DoG)\"),mdx(\"p\",null,mdx(\"a\",a({parentName:\"p\"},{href:\"https://en.wikipedia.org/wiki/Difference_of_Gaussians\"}),\"Difference of Gaussians (DoG)\"),\" is the difference of two Gaussian kernel convoluted images. DoG image is obtained by subtracting two Gaussian blurred images with different kernel radius and variance.\"),mdx(\"p\",null,\"Normally \",mdx(\"span\",a({parentName:\"p\"},{className:\"math math-inline\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"katex\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"katex-mathml\"}),mdx(\"math\",a({parentName:\"span\"},{xmlns:\"http://www.w3.org/1998/Math/MathML\"}),mdx(\"semantics\",{parentName:\"math\"},mdx(\"mrow\",{parentName:\"semantics\"},mdx(\"msub\",{parentName:\"mrow\"},mdx(\"mi\",{parentName:\"msub\"},\"I\"),mdx(\"mrow\",{parentName:\"msub\"},mdx(\"mi\",{parentName:\"mrow\"},\"d\"),mdx(\"mi\",{parentName:\"mrow\"},\"o\"),mdx(\"mi\",{parentName:\"mrow\"},\"g\")))),mdx(\"annotation\",a({parentName:\"semantics\"},{encoding:\"application/x-tex\"}),\"I_{dog}\")))),mdx(\"span\",a({parentName:\"span\"},{className:\"katex-html\",\"aria-hidden\":\"true\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"base\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"strut\",style:{height:\"0.969438em\",verticalAlign:\"-0.286108em\"}})),mdx(\"span\",a({parentName:\"span\"},{className:\"mord\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mathdefault\",style:{marginRight:\"0.07847em\"}}),\"I\"),mdx(\"span\",a({parentName:\"span\"},{className:\"msupsub\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist-t vlist-t2\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist-r\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist\",style:{height:\"0.3361079999999999em\"}}),mdx(\"span\",a({parentName:\"span\"},{style:{top:\"-2.5500000000000003em\",marginLeft:\"-0.07847em\",marginRight:\"0.05em\"}}),mdx(\"span\",a({parentName:\"span\"},{className:\"pstrut\",style:{height:\"2.7em\"}})),mdx(\"span\",a({parentName:\"span\"},{className:\"sizing reset-size6 size3 mtight\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mtight\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mathdefault mtight\"}),\"d\"),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mathdefault mtight\"}),\"o\"),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mathdefault mtight\",style:{marginRight:\"0.03588em\"}}),\"g\"))))),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist-s\"}),\"\\u200B\")),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist-r\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist\",style:{height:\"0.286108em\"}}),mdx(\"span\",{parentName:\"span\"})))))))))),\" (DoG of image) is calculated by subtracting \",mdx(\"span\",a({parentName:\"p\"},{className:\"math math-inline\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"katex\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"katex-mathml\"}),mdx(\"math\",a({parentName:\"span\"},{xmlns:\"http://www.w3.org/1998/Math/MathML\"}),mdx(\"semantics\",{parentName:\"math\"},mdx(\"mrow\",{parentName:\"semantics\"},mdx(\"msub\",{parentName:\"mrow\"},mdx(\"mi\",{parentName:\"msub\"},\"I\"),mdx(\"mrow\",{parentName:\"msub\"},mdx(\"mi\",{parentName:\"mrow\"},\"g\"),mdx(\"mn\",{parentName:\"mrow\"},\"1\")))),mdx(\"annotation\",a({parentName:\"semantics\"},{encoding:\"application/x-tex\"}),\"I_{g1}\")))),mdx(\"span\",a({parentName:\"span\"},{className:\"katex-html\",\"aria-hidden\":\"true\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"base\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"strut\",style:{height:\"0.969438em\",verticalAlign:\"-0.286108em\"}})),mdx(\"span\",a({parentName:\"span\"},{className:\"mord\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mathdefault\",style:{marginRight:\"0.07847em\"}}),\"I\"),mdx(\"span\",a({parentName:\"span\"},{className:\"msupsub\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist-t vlist-t2\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist-r\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist\",style:{height:\"0.301108em\"}}),mdx(\"span\",a({parentName:\"span\"},{style:{top:\"-2.5500000000000003em\",marginLeft:\"-0.07847em\",marginRight:\"0.05em\"}}),mdx(\"span\",a({parentName:\"span\"},{className:\"pstrut\",style:{height:\"2.7em\"}})),mdx(\"span\",a({parentName:\"span\"},{className:\"sizing reset-size6 size3 mtight\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mtight\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mathdefault mtight\",style:{marginRight:\"0.03588em\"}}),\"g\"),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mtight\"}),\"1\"))))),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist-s\"}),\"\\u200B\")),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist-r\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist\",style:{height:\"0.286108em\"}}),mdx(\"span\",{parentName:\"span\"})))))))))),\" and \",mdx(\"span\",a({parentName:\"p\"},{className:\"math math-inline\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"katex\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"katex-mathml\"}),mdx(\"math\",a({parentName:\"span\"},{xmlns:\"http://www.w3.org/1998/Math/MathML\"}),mdx(\"semantics\",{parentName:\"math\"},mdx(\"mrow\",{parentName:\"semantics\"},mdx(\"msub\",{parentName:\"mrow\"},mdx(\"mi\",{parentName:\"msub\"},\"I\"),mdx(\"mrow\",{parentName:\"msub\"},mdx(\"mi\",{parentName:\"mrow\"},\"g\"),mdx(\"mn\",{parentName:\"mrow\"},\"2\")))),mdx(\"annotation\",a({parentName:\"semantics\"},{encoding:\"application/x-tex\"}),\"I_{g2}\")))),mdx(\"span\",a({parentName:\"span\"},{className:\"katex-html\",\"aria-hidden\":\"true\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"base\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"strut\",style:{height:\"0.969438em\",verticalAlign:\"-0.286108em\"}})),mdx(\"span\",a({parentName:\"span\"},{className:\"mord\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mathdefault\",style:{marginRight:\"0.07847em\"}}),\"I\"),mdx(\"span\",a({parentName:\"span\"},{className:\"msupsub\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist-t vlist-t2\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist-r\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist\",style:{height:\"0.301108em\"}}),mdx(\"span\",a({parentName:\"span\"},{style:{top:\"-2.5500000000000003em\",marginLeft:\"-0.07847em\",marginRight:\"0.05em\"}}),mdx(\"span\",a({parentName:\"span\"},{className:\"pstrut\",style:{height:\"2.7em\"}})),mdx(\"span\",a({parentName:\"span\"},{className:\"sizing reset-size6 size3 mtight\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mtight\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mathdefault mtight\",style:{marginRight:\"0.03588em\"}}),\"g\"),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mtight\"}),\"2\"))))),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist-s\"}),\"\\u200B\")),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist-r\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist\",style:{height:\"0.286108em\"}}),mdx(\"span\",{parentName:\"span\"})))))))))),\" which are convoluted images with two different Gaussian kernels. But ImageMagick applies convolution after subtracting and scaling two gaussian kernels.\"),mdx(\"p\",null,\"So, we will first subtract two different Gaussian kernels, scale and normalize the dog-kernel to the zero-summing kernel (sum of all elements ~ 0.0)  and then apply convolution.\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-python\"}),`def normalize_kernel(kernel, k_width, k_height, scaling_factor = 1.0):\n    '''Zero-summing normalize kernel'''\n    \n    K_EPS = 1.0e-12\n    # positive and negative sum of kernel values\n    pos_range, neg_range = 0, 0\n    for i in range(k_width * k_height):\n        if abs(kernel[i]) < K_EPS:\n            kernel[i] = 0.0\n        if kernel[i] < 0:\n            neg_range += kernel[i]\n        else:\n            pos_range += kernel[i]\n    \n    # scaling factor for positive and negative range\n    pos_scale, neg_scale = pos_range, -neg_range\n    if abs(pos_range) >= K_EPS:\n        pos_scale = pos_range\n    else:\n        pos_sacle = 1.0\n    if abs(neg_range) >= K_EPS:\n        neg_scale = 1.0\n    else:\n        neg_scale = -neg_range\n        \n    pos_scale = scaling_factor / pos_scale\n    neg_scale = scaling_factor / neg_scale\n    \n    # scale kernel values for zero-summing kernel\n    for i in range(k_width * k_height):\n        if (not np.nan == kernel[i]):\n            kernel[i] *= pos_scale if kernel[i] >= 0 else neg_scale\n            \n    return kernel\n\ndef dog(img, k_size, sigma_1, sigma_2):\n    '''Difference of Gaussian by subtracting kernel 1 and kernel 2'''\n    \n    k_width = k_height = k_size\n    x = y = (k_width - 1) // 2\n    kernel = np.zeros(k_width * k_height)\n    \n    # first gaussian kernal\n    if sigma_1 > 0:\n        co_1 = 1 / (2 * sigma_1 * sigma_1)\n        co_2 = 1 / (2 * np.pi * sigma_1 * sigma_1)\n        i = 0\n        for v in range(-y, y + 1):\n            for u in range(-x, x + 1):\n                kernel[i] = np.exp(-(u*u + v*v) * co_1) * co_2\n                i += 1\n    # unity kernel\n    else:\n        kernel[x + y * k_width] = 1.0\n    \n    # subtract second gaussian from kernel\n    if sigma_2 > 0:\n        co_1 = 1 / (2 * sigma_2 * sigma_2)\n        co_2 = 1 / (2 * np.pi * sigma_2 * sigma_2)\n        i = 0\n        for v in range(-y, y + 1):\n            for u in range(-x, x + 1):\n                kernel[i] -= np.exp(-(u*u + v*v) * co_1) * co_2\n                i += 1\n    # unity kernel\n    else:\n        kernel[x + y * k_width] -= 1.0\n    \n    # zero-normalize scling kernel with scaling factor 1.0\n    norm_kernel = normalize_kernel(kernel, k_width, k_height, scaling_factor = 1.0)\n    \n    # apply filter with norm_kernel\n    return cv2.filter2D(img, -1, norm_kernel.reshape(k_width, k_height))\n`)),mdx(\"p\",null,\"Get Difference of Gaussian (DoG) for image by calling \",mdx(\"em\",{parentName:\"p\"},\"dog()\"),\" function with \",mdx(\"strong\",{parentName:\"p\"},\"radius = 15, sigma_1 = 100, sigma_2 = 0\"),\". Here \",mdx(\"strong\",{parentName:\"p\"},\"radius = 15\"),\" for both kernels, for first kernel, \",mdx(\"strong\",{parentName:\"p\"},\"sigma = 100\"),\", and for second kernel, \",mdx(\"strong\",{parentName:\"p\"},\"sigma = 0\"),\". Kernel with \",mdx(\"strong\",{parentName:\"p\"},\"sigma = 0\"),\" creates unity kernel means convolution with this kernel gives same image. \"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-python\"}),`dog_img = dog(img, 15, 100, 0)\n`)),mdx(\"p\",null,\"After applying DoG, the resultant image looks like\"),mdx(\"p\",null,mdx(\"img\",a({parentName:\"p\"},{src:\"whiteboard-enhance/difference-of-gaussian.jpg\",alt:\"Difference of Gaussian (DoG) Image:=:70:=:Difference of Gaussian (DoG) image\"}))),mdx(\"hr\",null),mdx(\"h3\",null,\"Negative Image\"),mdx(\"p\",null,\"For \",mdx(\"span\",a({parentName:\"p\"},{className:\"math math-inline\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"katex\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"katex-mathml\"}),mdx(\"math\",a({parentName:\"span\"},{xmlns:\"http://www.w3.org/1998/Math/MathML\"}),mdx(\"semantics\",{parentName:\"math\"},mdx(\"mrow\",{parentName:\"semantics\"},mdx(\"msub\",{parentName:\"mrow\"},mdx(\"mi\",{parentName:\"msub\"},\"I\"),mdx(\"mrow\",{parentName:\"msub\"},mdx(\"mi\",{parentName:\"mrow\"},\"d\"),mdx(\"mi\",{parentName:\"mrow\"},\"o\"),mdx(\"mi\",{parentName:\"mrow\"},\"g\")))),mdx(\"annotation\",a({parentName:\"semantics\"},{encoding:\"application/x-tex\"}),\"I_{dog}\")))),mdx(\"span\",a({parentName:\"span\"},{className:\"katex-html\",\"aria-hidden\":\"true\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"base\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"strut\",style:{height:\"0.969438em\",verticalAlign:\"-0.286108em\"}})),mdx(\"span\",a({parentName:\"span\"},{className:\"mord\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mathdefault\",style:{marginRight:\"0.07847em\"}}),\"I\"),mdx(\"span\",a({parentName:\"span\"},{className:\"msupsub\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist-t vlist-t2\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist-r\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist\",style:{height:\"0.3361079999999999em\"}}),mdx(\"span\",a({parentName:\"span\"},{style:{top:\"-2.5500000000000003em\",marginLeft:\"-0.07847em\",marginRight:\"0.05em\"}}),mdx(\"span\",a({parentName:\"span\"},{className:\"pstrut\",style:{height:\"2.7em\"}})),mdx(\"span\",a({parentName:\"span\"},{className:\"sizing reset-size6 size3 mtight\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mtight\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mathdefault mtight\"}),\"d\"),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mathdefault mtight\"}),\"o\"),mdx(\"span\",a({parentName:\"span\"},{className:\"mord mathdefault mtight\",style:{marginRight:\"0.03588em\"}}),\"g\"))))),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist-s\"}),\"\\u200B\")),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist-r\"}),mdx(\"span\",a({parentName:\"span\"},{className:\"vlist\",style:{height:\"0.286108em\"}}),mdx(\"span\",{parentName:\"span\"})))))))))),\", get a negative image which is just an inversion of colors (255 - image).\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-python\"}),`def negate(img):\n    '''Negative of image'''\n    \n    return cv2.bitwise_not(img)\n`)),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-python\"}),`negative_img = negate(dog_img)\n`)),mdx(\"p\",null,`The result of the inversion image is\n`,mdx(\"img\",a({parentName:\"p\"},{src:\"whiteboard-enhance/negative.jpg\",alt:\"Negative image:=:70:=:Negative image\"}))),mdx(\"p\",null,\"Image content is not much visible as we inverted an image whose most of the pixels are black. So, to improve the contrast, we apply contrast-stretch enhancement for the negative image.\"),mdx(\"hr\",null),mdx(\"h3\",null,\"Contrast Stretching\"),mdx(\"p\",null,\"Contrast stretching of an image is the same as histogram equalization but we cap some percentage of pixel values to black (0) and white (255).\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-python\"}),`def get_black_white_indices(hist, tot_count, black_count, white_count):\n    '''Blacking and Whiting out indices same as color balance'''\n\n    black_ind = 0\n    white_ind = 255\n    co = 0\n    for i in range(len(hist)):\n        co += hist[i]\n        if co > black_count:\n            black_ind = i\n            break\n            \n    co = 0\n    for i in range(len(hist) - 1, -1, -1):\n        co += hist[i]\n        if co > (tot_count - white_count):\n            white_ind = i\n            break\n    \n    return [black_ind, white_ind]\n\ndef contrast_stretch(img, black_point, white_point):\n    '''Contrast stretch image with black and white cap'''\n    \n    tot_count = img.shape[0] * img.shape[1]\n    black_count = tot_count * black_point / 100\n    white_count= tot_count * white_point / 100\n    ch_hists = []\n    # calculate histogram for each channel\n    for ch in cv2.split(img):\n        ch_hists.append(cv2.calcHist([ch], [0], None, [256], (0, 256)).flatten().tolist())\n    \n    # get black and white percentage indices\n    black_white_indices = []\n    for hist in ch_hists:\n        black_white_indices.append(get_black_white_indices(hist, tot_count, black_count, white_count))\n        \n    stretch_map = np.zeros((3, 256), dtype = 'uint8')\n    \n    # stretch histogram \n    for curr_ch in range(len(black_white_indices)):\n        black_ind, white_ind = black_white_indices[curr_ch]\n        for i in range(stretch_map.shape[1]):\n            if i < black_ind:\n                stretch_map[curr_ch][i] = 0\n            else:\n                if i > white_ind:\n                    stretch_map[curr_ch][i] = 255\n                else:\n                    if (white_ind - black_ind) > 0:\n                        stretch_map[curr_ch][i] = round((i - black_ind) / (white_ind - black_ind)) * 255\n                    else:\n                        stretch_map[curr_ch][i] = 0\n    \n    # stretch image\n    ch_stretch = []\n    for i, ch in enumerate(cv2.split(img)):\n        ch_stretch.append(cv2.LUT(ch, stretch_map[i]))\n        \n    return cv2.merge(ch_stretch)\n`)),mdx(\"p\",null,\"For each image channel, calculate cummulative histogram sum, and then cap pixels based on \",mdx(\"strong\",{parentName:\"p\"},\"black_point = 2\"),\" and \",mdx(\"strong\",{parentName:\"p\"},\"white_point = 99.5\"),\" percentage.\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-python\"}),`contrast_stretch_img = contrast_stretch(negative_img, 2, 99.5)\n`)),mdx(\"p\",null,\"Negative image after contrast stretching is\"),mdx(\"p\",null,mdx(\"img\",a({parentName:\"p\"},{src:\"whiteboard-enhance/contrast-stretch.jpg\",alt:\"Contrast stretch image:=:70:=:Contrast strech image\"}))),mdx(\"hr\",null),mdx(\"h3\",null,\"Gaussin Blur & Gamma Correction\"),mdx(\"p\",null,\"Contrast stretching image contains noise, so blur the image with Gaussian kernel. As Gaussian distribution kernel can be linearly separable, we apply convolution with the same 1D-kernel along the x-axis and y-axis for performance (negligible for small kernels and low-res images).\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-python\"}),`def fast_gaussian_blur(img, ksize, sigma):\n    '''Gussian blur using linear separable property of Gaussian distribution'''\n    \n    kernel_1d = cv2.getGaussianKernel(ksize, sigma)\n    return cv2.sepFilter2D(img, -1, kernel_1d, kernel_1d)\n\ndef gamma(img, gamma_value):\n    '''Gamma correction of image'''\n    \n    i_gamma = 1 / gamma_value\n    lut = np.array([((i / 255) ** i_gamma) * 255 for i in np.arange(0, 256)], dtype = 'uint8')\n    return cv2.LUT(img, lut)\n`)),mdx(\"p\",null,\"Apply Gaussian blur with \",mdx(\"strong\",{parentName:\"p\"},\"kernel_size = 3\"),\" and \",mdx(\"strong\",{parentName:\"p\"},\"sigma = 1\"),\".\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-python\"}),`blur_img = fast_gaussian_blur(contrast_stretch_img, 3, 1)\n`)),mdx(\"p\",null,\"Blurred image after noise suppression is\"),mdx(\"p\",null,mdx(\"img\",a({parentName:\"p\"},{src:\"whiteboard-enhance/gaussian-blur.jpg\",alt:\"Gaussian blur image:=:70:=:Blurred image\"}))),mdx(\"p\",null,\"Now apply Gamma correction to enhance the blurred image with \",mdx(\"strong\",{parentName:\"p\"},\"gamma_value = 1.1\"),\".\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-python\"}),`gamma_img = gamma(blur_img, 1.1)\n`)),mdx(\"p\",null,\"Blurred image Gamma corrected looks like\"),mdx(\"p\",null,mdx(\"img\",a({parentName:\"p\"},{src:\"whiteboard-enhance/gamma-correction.jpg\",alt:\"Gamma correction:=:70:=:Gamma corrected image\"}))),mdx(\"hr\",null),mdx(\"h3\",null,\"Color Balance\"),mdx(\"p\",null,\"Color balance of an image is same as contrast-stretching method above but they are different in implementation. Above contrast-stretching is an implementation based on \",mdx(\"a\",a({parentName:\"p\"},{href:\"https://imagemagick.org/api/MagickCore/enhance_8c.html\"}),\"ImageMagick-ContrastStretchImage()\"),\", and \",mdx(\"a\",a({parentName:\"p\"},{href:\"https://gist.github.com/DavidYKay/9dad6c4ab0d8d7dbf3dc\"}),\"color balance\"),\" is based on \",mdx(\"a\",a({parentName:\"p\"},{href:\"https://www.ipol.im/pub/art/2011/llmps-scb/article.pdf\"}),\"Simplest Color Balance\"),\".\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-python\"}),`def color_balance(img, low_per, high_per):\n    '''Contrast stretch image by histogram equilization with black and white cap'''\n    \n    tot_pix = img.shape[1] * img.shape[0]\n    # no.of pixels to black-out and white-out\n    low_count = tot_pix * low_per / 100\n    high_count = tot_pix * (100 - high_per) / 100\n    \n    cs_img = []\n    # for each channel, apply contrast-stretch\n    for ch in cv2.split(img):\n        # cummulative histogram sum of channel\n        cum_hist_sum = np.cumsum(cv2.calcHist([ch], [0], None, [256], (0, 256)))\n\n        # find indices for blacking and whiting out pixels\n        li, hi = np.searchsorted(cum_hist_sum, (low_count, high_count))\n        if (li == hi):\n            cs_img.append(ch)\n            continue\n        # lut with min-max normalization for [0-255] bins\n        lut = np.array([0 if i < li \n                        else (255 if i > hi else round((i - li) / (hi - li) * 255)) \n                        for i in np.arange(0, 256)], dtype = 'uint8')\n        # constrast-stretch channel\n        cs_ch = cv2.LUT(ch, lut)\n        cs_img.append(cs_ch)\n        \n    return cv2.merge(cs_img)\n`)),mdx(\"p\",null,\"Enhance image by passing Gamma corrected image to \",mdx(\"strong\",{parentName:\"p\"},\"color_balance()\"),\" with parameters \",mdx(\"strong\",{parentName:\"p\"},\"low_per = 2\"),\" and \",mdx(\"strong\",{parentName:\"p\"},\"high_per = 1\"),\".\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-python\"}),`color_balanced_img = color_balance(gamma_img, 2, 1)\n`)),mdx(\"p\",null,`The final enhanced whiteboard image is\n`,mdx(\"img\",a({parentName:\"p\"},{src:\"whiteboard-enhance/whiteboard-image-enhanced.jpg\",alt:\"Whiteboard image enhance:=:70:=:Whiteboard image enhanced\"}))),mdx(\"p\",null,\"You can find out full code at my Github repository file \",mdx(\"a\",a({parentName:\"p\"},{href:\"https://github.com/santhalakshminarayana/whiteboard-image-enhance/blob/main/whiteboard_image_enhance.py\"}),\"whiteboard_image_enhance.py\")),mdx(\"hr\",null),mdx(\"h2\",null,\"Results\"),mdx(\"p\",null,mdx(\"img\",a({parentName:\"p\"},{src:\"whiteboard-enhance/img_2.jpg\",alt:\"img_2:=:100\"}))),mdx(\"p\",null,mdx(\"img\",a({parentName:\"p\"},{src:\"whiteboard-enhance/img_3.jpg\",alt:\"img_3:=:100\"}))),mdx(\"p\",null,mdx(\"img\",a({parentName:\"p\"},{src:\"whiteboard-enhance/img_4.jpg\",alt:\"img_4:=:100\"}))))}MDXContent.isMDXComponent=!0;\n","scope":{}},"id":"whiteboard-image-enhancement-opencv-python"},"__N_SSG":true}