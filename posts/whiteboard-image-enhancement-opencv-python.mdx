---
title: "Whiteboard Image Enhancement using OpenCV"
description: "Enhance whiteboard images taken from mobile using OpenCV."
imgName: "whiteboard-enhance/whiteboard-image-enhancement.jpg"
date: "Oct 19, 2021"
tags: ['image-processing', 'opencv']
keywords: ['whiteboard', 'whiteboard-enhance', 'image-enhance', 'image-processing', 'opencv', 'python', 'difference-of-guassian', 'dog', 'contrast-stretch', 'color-balance']
---

![Whiteboard image enhancement in Python](whiteboard-enhance/whiteboard-image-enhancement.jpg)

# Whiteboard image enhancement using OpenCV

Whiteboard images generally contain less contrast and low brightness as they would be captured in mobile under normal room light conditions. Enhancing whiteboard images makes text readable and gives an image with high contrast and brightness. 

We will apply different image-processing techniques to enhance whiteboard images using OpenCV in Python. From this [whiteboard-cleaner](https://gist.github.com/lelandbatey/8677901) gist that enhances whiteboard images using [ImageMagick](https://imagemagick.org/), we will implement those ImageMagick methods in Python.

In that script, the following ImageMagick functions were used to enhance whiteboard images

```shell
-morphology Convolve DoG:15,100,0 -negate -normalize -blur 0x1 -channel RBG -level 60%,91%,0.1
``` 
Above command applies image enhancing functions in order 
- **-morphology Convolve DoG:15, 100, 0**: Difference of Gaussian (DoG) with kernel_radius=15, sigma1=100, and sigma2=0
- **-negate**: Negative of image
- **-normalize**: Contrast stretch image with black=0.15% and white=0.05%
- **-blur 0x1**: Gaussian blur with sigma=1
- **-level 60%,91%,0.1: Stretch image with black=60% and white=91%, and Gamma correction by gamma=0.1

As I found some difficulty for exactly converting the ImageMagick C code to Python, I have changed the order and parameters that would give close results.

---

We will apply series of image-processing methods and effects to enhance whiteboard images in the following order
- Difference of Gaussian (DoG)
- Negative effect
- Contrast Stretching
- Gaussian blur
- Gamma correction
- Color balance

You can find the full code in my Github repository [whiteboard-image-enhance](https://github.com/santhalakshminarayana/whiteboard-image-enhance)

### Import packages and read image

```python
import cv2
import numpy as np

img = cv2.imread('input.jpg')
```

![Whiteboard image input:=:70:=:Input Whiteboard image](whiteboard-enhance/whiteboard-image.jpg)

### Difference of Gaussian (DoG)

[Difference of Gaussians (DoG)](https://en.wikipedia.org/wiki/Difference_of_Gaussians) is the difference of two Gaussian kernel convoluted images. DoG image is obtained by subtracting two Gaussian blurred images with different kernel radius and variance.

Normally $I_{dog}$ (DoG of image) is calculated by subtracting $I_{g1}$ and $I_{g2}$ which are convoluted images with two different Gaussian kernels. But ImageMagick applies convolution after subtracting and scaling two gaussian kernels.

So, we will first subtract two different Gaussian kernels, scale and normalize the dog-kernel to the zero-summing kernel (sum of all elements ~ 0.0)  and then apply convolution.

```python
def normalize_kernel(kernel, k_width, k_height, scaling_factor = 1.0):
    '''Zero-summing normalize kernel'''
    
    K_EPS = 1.0e-12
    # positive and negative sum of kernel values
    pos_range, neg_range = 0, 0
    for i in range(k_width * k_height):
        if abs(kernel[i]) < K_EPS:
            kernel[i] = 0.0
        if kernel[i] < 0:
            neg_range += kernel[i]
        else:
            pos_range += kernel[i]
    
    # scaling factor for positive and negative range
    pos_scale, neg_scale = pos_range, -neg_range
    if abs(pos_range) >= K_EPS:
        pos_scale = pos_range
    else:
        pos_sacle = 1.0
    if abs(neg_range) >= K_EPS:
        neg_scale = 1.0
    else:
        neg_scale = -neg_range
        
    pos_scale = scaling_factor / pos_scale
    neg_scale = scaling_factor / neg_scale
    
    # scale kernel values for zero-summing kernel
    for i in range(k_width * k_height):
        if (not np.nan == kernel[i]):
            kernel[i] *= pos_scale if kernel[i] >= 0 else neg_scale
            
    return kernel

def dog(img, k_size, sigma_1, sigma_2):
    '''Difference of Gaussian by subtracting kernel 1 and kernel 2'''
    
    k_width = k_height = k_size
    x = y = (k_width - 1) // 2
    kernel = np.zeros(k_width * k_height)
    
    # first gaussian kernal
    if sigma_1 > 0:
        co_1 = 1 / (2 * sigma_1 * sigma_1)
        co_2 = 1 / (2 * np.pi * sigma_1 * sigma_1)
        i = 0
        for v in range(-y, y + 1):
            for u in range(-x, x + 1):
                kernel[i] = np.exp(-(u*u + v*v) * co_1) * co_2
                i += 1
    # unity kernel
    else:
        kernel[x + y * k_width] = 1.0
    
    # subtract second gaussian from kernel
    if sigma_2 > 0:
        co_1 = 1 / (2 * sigma_2 * sigma_2)
        co_2 = 1 / (2 * np.pi * sigma_2 * sigma_2)
        i = 0
        for v in range(-y, y + 1):
            for u in range(-x, x + 1):
                kernel[i] -= np.exp(-(u*u + v*v) * co_1) * co_2
                i += 1
    # unity kernel
    else:
        kernel[x + y * k_width] -= 1.0
    
    # zero-normalize scling kernel with scaling factor 1.0
    norm_kernel = normalize_kernel(kernel, k_width, k_height, scaling_factor = 1.0)
    
    # apply filter with norm_kernel
    return cv2.filter2D(img, -1, norm_kernel.reshape(k_width, k_height))
``` 

Get Difference of Gaussian (DoG) for image by calling *dog()* function with **radius = 15, sigma_1 = 100, sigma_2 = 0**. Here **radius = 15** for both kernels, for first kernel, **sigma = 100**, and for second kernel, **sigma = 0**. Kernel with **sigma = 0** creates unity kernel means convolution with this kernel gives same image. 

```python
dog_img = dog(img, 15, 100, 0)
```

After applying DoG, the resultant image looks like

![Difference of Gaussian (DoG) Image:=:70:=:Difference of Gaussian (DoG) image](whiteboard-enhance/difference-of-gaussian.jpg)

---

### Negative Image

For $I_{dog}$, get a negative image which is just an inversion of colors (255 - image).

```python
def negate(img):
    '''Negative of image'''
    
    return cv2.bitwise_not(img)
```

```python
negative_img = negate(dog_img)
```

The result of the inversion image is
![Negative image:=:70:=:Negative image](whiteboard-enhance/negative.jpg)

Image content is not much visible as we inverted an image whose most of the pixels are black. So, to improve the contrast, we apply contrast-stretch enhancement for the negative image.

---

### Contrast Stretching

Contrast stretching of an image is the same as histogram equalization but we cap some percentage of pixel values to black (0) and white (255).

```python
def get_black_white_indices(hist, tot_count, black_count, white_count):
    '''Blacking and Whiting out indices same as color balance'''

    black_ind = 0
    white_ind = 255
    co = 0
    for i in range(len(hist)):
        co += hist[i]
        if co > black_count:
            black_ind = i
            break
            
    co = 0
    for i in range(len(hist) - 1, -1, -1):
        co += hist[i]
        if co > (tot_count - white_count):
            white_ind = i
            break
    
    return [black_ind, white_ind]

def contrast_stretch(img, black_point, white_point):
    '''Contrast stretch image with black and white cap'''
    
    tot_count = img.shape[0] * img.shape[1]
    black_count = tot_count * black_point / 100
    white_count= tot_count * white_point / 100
    ch_hists = []
    # calculate histogram for each channel
    for ch in cv2.split(img):
        ch_hists.append(cv2.calcHist([ch], [0], None, [256], (0, 256)).flatten().tolist())
    
    # get black and white percentage indices
    black_white_indices = []
    for hist in ch_hists:
        black_white_indices.append(get_black_white_indices(hist, tot_count, black_count, white_count))
        
    stretch_map = np.zeros((3, 256), dtype = 'uint8')
    
    # stretch histogram 
    for curr_ch in range(len(black_white_indices)):
        black_ind, white_ind = black_white_indices[curr_ch]
        for i in range(stretch_map.shape[1]):
            if i < black_ind:
                stretch_map[curr_ch][i] = 0
            else:
                if i > white_ind:
                    stretch_map[curr_ch][i] = 255
                else:
                    if (white_ind - black_ind) > 0:
                        stretch_map[curr_ch][i] = round((i - black_ind) / (white_ind - black_ind)) * 255
                    else:
                        stretch_map[curr_ch][i] = 0
    
    # stretch image
    ch_stretch = []
    for i, ch in enumerate(cv2.split(img)):
        ch_stretch.append(cv2.LUT(ch, stretch_map[i]))
        
    return cv2.merge(ch_stretch)
```

For each image channel, calculate cummulative histogram sum, and then cap pixels based on **black_point = 2** and **white_point = 99.5** percentage.

```python
contrast_stretch_img = contrast_stretch(negative_img, 2, 99.5)
``` 

Negative image after contrast stretching is

![Contrast stretch image:=:70:=:Contrast strech image](whiteboard-enhance/contrast-stretch.jpg)

---

### Gaussin Blur & Gamma Correction

Contrast stretching image contains noise, so blur the image with Gaussian kernel. As Gaussian distribution kernel can be linearly separable, we apply convolution with the same 1D-kernel along the x-axis and y-axis for performance (negligible for small kernels and low-res images).

```python
def fast_gaussian_blur(img, ksize, sigma):
    '''Gussian blur using linear separable property of Gaussian distribution'''
    
    kernel_1d = cv2.getGaussianKernel(ksize, sigma)
    return cv2.sepFilter2D(img, -1, kernel_1d, kernel_1d)

def gamma(img, gamma_value):
    '''Gamma correction of image'''
    
    i_gamma = 1 / gamma_value
    lut = np.array([((i / 255) ** i_gamma) * 255 for i in np.arange(0, 256)], dtype = 'uint8')
    return cv2.LUT(img, lut)
```

Apply Gaussian blur with **kernel_size = 3** and **sigma = 1**.

```python
blur_img = fast_gaussian_blur(contrast_stretch_img, 3, 1)
```

Blurred image after noise suppression is

![Gaussian blur image:=:70:=:Blurred image](whiteboard-enhance/gaussian-blur.jpg)

Now apply Gamma correction to enhance the blurred image with **gamma_value = 1.1**.

```python
gamma_img = gamma(blur_img, 1.1)
```

Blurred image Gamma corrected looks like

![Gamma correction:=:70:=:Gamma corrected image](whiteboard-enhance/gamma-correction.jpg)

---

### Color Balance

Color balance of an image is same as contrast-stretching method above but they are different in implementation. Above contrast-stretching is an implementation based on [ImageMagick-ContrastStretchImage()](https://imagemagick.org/api/MagickCore/enhance_8c.html), and [color balance](https://gist.github.com/DavidYKay/9dad6c4ab0d8d7dbf3dc) is based on [Simplest Color Balance](https://www.ipol.im/pub/art/2011/llmps-scb/article.pdf).

```python
def color_balance(img, low_per, high_per):
    '''Contrast stretch image by histogram equilization with black and white cap'''
    
    tot_pix = img.shape[1] * img.shape[0]
    # no.of pixels to black-out and white-out
    low_count = tot_pix * low_per / 100
    high_count = tot_pix * (100 - high_per) / 100
    
    cs_img = []
    # for each channel, apply contrast-stretch
    for ch in cv2.split(img):
        # cummulative histogram sum of channel
        cum_hist_sum = np.cumsum(cv2.calcHist([ch], [0], None, [256], (0, 256)))

        # find indices for blacking and whiting out pixels
        li, hi = np.searchsorted(cum_hist_sum, (low_count, high_count))
        if (li == hi):
            cs_img.append(ch)
            continue
        # lut with min-max normalization for [0-255] bins
        lut = np.array([0 if i < li 
                        else (255 if i > hi else round((i - li) / (hi - li) * 255)) 
                        for i in np.arange(0, 256)], dtype = 'uint8')
        # constrast-stretch channel
        cs_ch = cv2.LUT(ch, lut)
        cs_img.append(cs_ch)
        
    return cv2.merge(cs_img)
```

Enhance image by passing Gamma corrected image to **color_balance()** with parameters **low_per = 2** and **high_per = 1**.

```python
color_balanced_img = color_balance(gamma_img, 2, 1)
```

The final enhanced whiteboard image is
![Whiteboard image enhance:=:70:=:Whiteboard image enhanced](whiteboard-enhance/whiteboard-image-enhanced.jpg)

You can find out full code at my Github repository file [whiteboard_image_enhance.py](https://github.com/santhalakshminarayana/whiteboard-image-enhance/blob/main/whiteboard_image_enhance.py)

---

## Results

![img_2:=:100](whiteboard-enhance/img_2.jpg)

![img_3:=:100](whiteboard-enhance/img_3.jpg)

![img_4:=:100](whiteboard-enhance/img_4.jpg)