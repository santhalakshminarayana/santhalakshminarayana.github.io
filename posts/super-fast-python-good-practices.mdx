---
title: "Super fast Python (Part-2): Good Practices"
description: "Write Python programs by following good practices to run code incredibly faster."
imgName: "super-fast-python-good-practices/super-fast-python-good-practices.jpg"
date: "Nov 9, 2022"
tags: ['python-performance', 'python']
keywords: ['python-performance', 'python-optimize', 'python', 'fast-python', 'speed']
---

![Super fast Python: Good Practices](super-fast-python-good-practices/super-fast-python-good-practices.jpg)

###### Published on: **Nov 9, 2022**

# Super fast Python (Part-2): Good practices

In the earlier post on [why Python is slow?](https://santhalakshminarayana.github.io/blog/super-fast-python-why-python-slow), we discussed slowness is in Python due to its internal design of some essential components like GIL, dynamic typing, and interpretation.

In this blog, we discuss some good practices to speed up Python incredibly faster.

This is the second post in the series on Python performance and Optimization. The series points out the utilization of inbuilt libraries, low-level code conversions, and other Python implementations to speed-up Python. The other posts included in this series are 

- (Part-1): [Why Python is slow?](https://santhalakshminarayana.github.io/blog/super-fast-python-why-python-slow)
- (Part-2): Good practices to write fast Python code (this post)
- (Part-3): [Multi-processing in Python](https://santhalakshminarayana.github.io/blog/super-fast-python-multi-processing)
- (Part-4): [Use Cython to get speed as fast as C](https://santhalakshminarayana.github.io/blog/super-fast-python-cython)
- (Part-5): [Use Numba to speed up Python Functions and Numeric calculations](https://santhalakshminarayana.github.io/blog/super-fast-python-numba)

The following section describes the various good practices one can use to make Python super speed (up to 30% or more) without any external support like PyPy, Cython, Numpy, etc.

## Python good practices for super fast code

### Use built-in data structures and libraries

As Python data types are implemented directly in **C**, using the built-in types like list, map, and trees, compared to custom types we define, really helps the program to run faster.

Also, use built-in libraries for common algorithms like counting the duplicates, summing all list elements, finding the maximum element, etc, because these are all already written in **C** and compiled which makes these functions run faster than custom functions we write.

```python
from random import randint

rand_nums = [randint(1, 100) for _ in range(100000)]
```
Create 100000 random numbers between 1 and 100.

```python
%%timeit
cc = 0
for i in range(len(rand_nums)):
    cc += rand_nums[i]
```
```python:output
6.02 ms ± 94 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
```

Manually summing up the all numbers over running a loop takes approximately 6ms.

```python
%%timeit
cc = sum(rand_nums)
```
```python:output
332 µs ± 15 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
```

Using built-in *sum()* takes only 0.3ms approximately.

### Local Variables vs Global Variables

When we call a function (a routine), the system pauses the code execution at the call site in the current routine (say **main()**) where the call has been made and places the called function at the top of the call stack. Imagine if we have defined numerous global variables and made multiple function calls. The system has to make sure that all these global variables should be available for any routine placed in the call stack at all times. The system has to provide a lookup mechanism for both local and global variables for each routine. And with global variables, this lookup mechanism may take some time than local variables.

### Import the sub-modules and functions directly

When importing any module to use its sub-modules, classes, or functions, import them directly instead of importing just the module. When accessing objects using *.*, it triggers dictionary lookup using *\_\_getattribute\_\_*. If we call the object multiple times using *.*, that may increase the program time.

```python
# instead of this
import abc
def_obj = abc.Def()

# do this
from abc import Def
def_obj = Def()
```

### Limit the usage of '.'

Speaking of the lookup time with the module's object references, the same can be applied to the referencing of properties and functions of an object(both custom and in-built). 

```python
%%timeit
ll = []
for i in range(len(rand_nums)):
    ll.append(rand_nums[i])
```
```python:output
6.67 ms ± 84.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
```

Adding the list elements by appending with *list.append()* takes more time than following code because the function is assigned to a variable (functions are first-class citizens in Python) and used inside the loop. This simple practice avoids referencing the functions with **'.'** too often and finally limits the need for dictionary lookup.

```python
%%timeit
ll = []
ll_append = ll.append
for i in range(len(rand_nums)):
    ll_append(rand_nums[i])
```
```python:output
5.45 ms ± 116 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
```

### Avoid writing functions unnecessary

It's good to have code separability by using functions for each independent task. But, as functions in Python are relatively more expensive than C/C++ due to boxing and unboxing dynamic variables and other factors, limit writing functions for unnecessary cases like one-liners. 

### Don't wrap lambdas around functions

Overuse or misuse of lambdas is not a good practice. It's common to wrap functions inside lambdas which do the same thing without wrapping.

Consider the following two functions for sorting a list based on absolute values.

```python
def fun_sort_with_lambda(l):
    return sorted(l, key=lambda x: abs(x))

def fun_sort_without_lambda(l):
    return sorted(l, key=abs)
```

If we look at the CPython bytecode for the above functions with lambda expression passed as a key and with *abs* function object as a key,

```python
>>> from dis import dis
>>> dis(fun_sort_with_lambda)
  2           0 LOAD_GLOBAL              0 (sorted)
              2 LOAD_FAST                0 (l)
              4 LOAD_CONST               1 (<code object <lambda> at 0x7fc51b3a19d0, file "<ipython-input-62-c4147c242c71>", line 2>)
              6 LOAD_CONST               2 ('fun_sort_with_lambda.<locals>.<lambda>')
              8 MAKE_FUNCTION            0
             10 LOAD_CONST               3 (('key',))
             12 CALL_FUNCTION_KW         2
             14 RETURN_VALUE

Disassembly of <code object <lambda> at 0x7fc51b3a19d0, file "<ipython-input-62-c4147c242c71>", line 2>:
  2           0 LOAD_GLOBAL              0 (abs)
              2 LOAD_FAST                0 (x)
              4 CALL_FUNCTION            1
              6 RETURN_VALUE

>>> dis(fun_sort_without_lambda)
  2           0 LOAD_GLOBAL              0 (sorted)
              2 LOAD_FAST                0 (l)
              4 LOAD_GLOBAL              1 (abs)
              6 LOAD_CONST               1 (('key',))
              8 CALL_FUNCTION_KW         2
             10 RETURN_VALUE
```

for the function *fun_sort_with_lambda*, there is an additional function has been generated for lambda. We can avoid this function generation without using lambda as we can see in function *fun_sort_without_lambda*. 

### List comprehension is fast

When operating over lists like data structures, list comprehension is faster than traditional methods like looping, functional programming, etc.

```python
%%timeit
rand_nums = []
for _ in range(1000):
    rand_nums.append(randint(1, 100))
```
```output
603 µs ± 15.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
```

The list comprehension version of the above code snippet runs faster.

```python:output
%%timeit
rand_nums = [randint(1, 100) for _ in range(1000)]
```
```python:output
565 µs ± 11 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
```

---

The optimization practices are not limited to the above approaches. We can check how much time it is taking for each line by using libraries like [CProfile](https://docs.python.org/3/library/profile.html) and making changes to run faster. In the next blog, we discuss how to improve Python computing efficiency using multiprocessing.

---

### References
- [Python Speed](https://wiki.python.org/moin/PythonSpeed)
- [Python Optimization](https://aglowiditsolutions.com/blog/python-optimization/)
- [Making Python Programs Blazingly Fast](https://martinheinz.dev/blog/13)